{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fillers = [\n",
    "        r\"\\bright\\b\\s?\",\n",
    "        r\"\\byou know\\b\\s?\",\n",
    "        r\"\\bi think\\b\\s?\",\n",
    "        r\"\\bbut i think\\b\\s?\",\n",
    "        r\"\\bso to speak\\b\\s?\",\n",
    "        r\"\\blike\\b\\s?\",\n",
    "        r\"\\bi mean\\b\\s?\",\n",
    "        r\"\\bso\\b\\s?\",\n",
    "        r\"\\bactually\\b\\s?\",\n",
    "        r\"\\bbasically\\b\\s?\",\n",
    "        r\"\\bokay\\b\\s?\",\n",
    "        r\"\\byeah\\b\\s?\",\n",
    "        r\"\\byeah okay\\b\\s?\",\n",
    "        r\"\\byes\\b\\s?\",\n",
    "        r\"\\bthe\\b\\s?\",\n",
    "        r\"\\band\\b\\s?\",\n",
    "        \n",
    "        r\"\\bchuckle\\b\\s?\",\n",
    "        r\"\\blaughter\\b\\s?\",\n",
    "        r\"\\bpause\\b\\s?\",\n",
    "        r\"\\bnoise\\b\\s?\",\n",
    "        r\"\\bmusic\\b\\s?\",\n",
    "        r\"\\bapplause\\b\\s?\",\n",
    "        r\"\\bvocalization\\b\\s?\",\n",
    "        r\"\\bvideo playback\\b\\s?\",\n",
    "        r\"\\bautomated voice\\b\\s?\",\n",
    "        r\"\\bforeign language\\b\\s?\",\n",
    "        r\"\\boverlapping conversation\\b\\s?\",\n",
    "        r\"\\bbackground conversation\\b\\s?\",\n",
    "        r\"\\bstart-paren\\b\\s?\",\n",
    "        r\"\\bend-paren\\b\\s?\",\n",
    "        \n",
    "        r\"\\ba\\b\\s?\",\n",
    "        r\"\\bto\\b\\s?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baddos = '|'.join(fillers)\n",
    "#re.sub(baddos,'',st)\n",
    "#substitute_finder.sub(match_to_substitution, st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "st = 'my the s23 like 2 half-hearted I am 008966 a man man-whore 00089 e s   s2  a s3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my the s23 like 2 half-hearted I am 008966 a man man-whore 00089 e s   s2  a'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('\\s*$','',st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fake = np.ones([1,300])*np.random.randn(300)\n",
    "fake2 = np.ones([1,300])*np.random.randn(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fake_mean = np.asarray(np.mean(fake,axis=0)).reshape([-1,1])\n",
    "fake2_mean = np.asarray(np.mean(fake2,axis=0)).reshape([-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zips = np.ones(300).reshape([-1,1])\n",
    "zips2 = np.ones(300).reshape([-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94604251334663247"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(fake_mean,fake2_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2204460492503131e-16"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(zips,zips2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "st = 'my the s23 like 2 half-hearted I am 008966 a man st man-whore 00089 e s s2 a s3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my the s23 like 2 half-hearted I am 008966 a man st man-whore 00089 e s s2 a s3'"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my the  like 2 half-hearted I am 008966 a man st man-whore 00089 e   a '"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"\\bs\\d{0,2}\\b\",'',st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my the speaker like digit half hearted I am timestamp one man st man whore timestamp e speaker speaker one speaker'"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = re.sub(r\"\\bs\\d{0,2}\\b\",'speaker',st)\n",
    "a = re.sub(r\"\\b\\d{5,6}\\b\",'timestamp',a)\n",
    "a = re.sub(r'\\d+','digit',a)\n",
    "a = re.sub(r'-',' ',a)\n",
    "a = re.sub(r\"\\ba\\b\",'one',a)\n",
    "a\n",
    "#re.sub(r\"\\s*$\",'',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.zeros(10)+1e-3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check.vocab_dict['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import euclidean_distances,confusion_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from fuzzywuzzy import fuzz\n",
    "import pandas as pd\n",
    "from pyemd import emd\n",
    "import tensorflow as tf\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "\n",
    "class error_checker():\n",
    "    \"\"\"\n",
    "    Error checker class that builds embeddings upon instantiation, is capable\n",
    "    of being retrained, making predictions, and inspecting performance.\n",
    "    expects data_path upon instantiation, which is a directory in which\n",
    "    the 3000000x300 pretrained Google News vectors binary file should be at\n",
    "    very least, and will create embeddings and vocab (embed.dat, embed.vocab)\n",
    "    in that directory if they do not exist. In order to perform training, the\n",
    "    class expects 'dataset.csv' as well, which should have no header, and\n",
    "    three entries per datapoint (Error [1 for minor, 2 for major],\n",
    "    String 1 [first transcription],String 2 [second transcription]). Some\n",
    "    files will be created as a result of training (model.ckpt, fuzzy.csv).\n",
    "    \"\"\"\n",
    "    def __init__(self,data_path):\n",
    "\n",
    "        self.data_path = data_path\n",
    "        self._save_path = os.path.join(self.data_path,'model.ckpt')\n",
    "        self.epsilon = 1e-4\n",
    "\n",
    "        binary_file = os.path.join(self.data_path,\n",
    "                                   'GoogleNews-vectors-negative300.bin')\n",
    "        w2v_dat = os.path.join(self.data_path,'embed.dat')\n",
    "        w2v_vocab = os.path.join(self.data_path,'embed.vocab')\n",
    "\n",
    "        if not os.path.exists(w2v_dat):\n",
    "            print(\"Caching word embeddings in memmapped format.                     Please be patient...\")\n",
    "            wv = Word2Vec.load_word2vec_format(\n",
    "                binary_file,binary=True)\n",
    "            fp = np.memmap(w2v_dat, dtype=np.double,\n",
    "                           mode='w+', shape=wv.syn0.shape)\n",
    "            fp[:] = wv.syn0[:]\n",
    "            with open(w2v_vocab, \"w\") as f:\n",
    "                for _, w in sorted((voc.index, word)                                    for word, voc in wv.vocab.items()):\n",
    "                    print(w, file=f)\n",
    "            del fp, wv\n",
    "\n",
    "        # create word embeddings and mapping of vocabulary item to index\n",
    "        self.embeddings = np.memmap(w2v_dat, dtype=np.float64,\n",
    "                                    mode=\"r\", shape=(3000000, 300))\n",
    "        with open(w2v_vocab) as f:\n",
    "            vocab_list = map(lambda string: string.strip(), f.readlines())\n",
    "        self.vocab_dict = {w: i for i, w in enumerate(vocab_list)}\n",
    "\n",
    "        # mean of 20 rarest words, used as a stand-in for pairwise distances\n",
    "        # if a word is out-of-vocabulary\n",
    "        avg_rare_word = np.mean(np.vstack(self.embeddings[-20:]),axis=0)\n",
    "        self.bad_row = np.asarray([avg_rare_word])\n",
    "\n",
    "    def _index_check(self,features):\n",
    "        total = 0\n",
    "        for word in features:\n",
    "            if word in self.vocab_dict:\n",
    "                total+=self.vocab_dict[word]\n",
    "        return total\n",
    "\n",
    "    def _get_dist(self,s_1,s_2):\n",
    "        \"\"\"Return counts of in-vocabulary and out-of-vocabulary items per\n",
    "        string, means of embeddings per string, and Word Mover's Distance\n",
    "        between the two. Word embeddings and mappings were created upon\n",
    "        initialization of the class instance, and WMD with emd()\n",
    "        (Earth Mover's Distance) from PyEMD. Final shape is [1,612].\n",
    "        \"\"\"\n",
    "\n",
    "        results_ = []\n",
    "        \n",
    "        ###############\n",
    "        #s_1 = re.sub(r\"\\bs\\d{0,2}\\b\",'speaker',s_1)\n",
    "        #s_1 = re.sub(r\"\\b\\d{5,6}\\b\",'timestamp',s_1)\n",
    "        #s_1 = re.sub(r'\\d+','digit',s_1)\n",
    "        s_1 = re.sub(r'-',' ',s_1)\n",
    "        s_1 = re.sub(r\"\\ba\\b\",'one',s_1)\n",
    "        \n",
    "        #s_2 = re.sub(r\"\\bs\\d{0,2}\\b\",'speaker',s_2)\n",
    "        #s_2 = re.sub(r\"\\b\\d{5,6}\\b\",'timestamp',s_2)\n",
    "        #s_2 = re.sub(r'\\d+','digit',s_2)\n",
    "        s_2 = re.sub(r'-',' ',s_2)\n",
    "        s_2 = re.sub(r\"\\ba\\b\",'one',s_2)\n",
    "        \n",
    "                \n",
    "        # from FuzzyWuzzy: ratio, partial, sort, set\n",
    "        fw_ratio = fuzz.ratio(s_1,s_2)\n",
    "        fw_partial = fuzz.partial_ratio(s_1,s_2)\n",
    "        fw_sort = fuzz.token_sort_ratio(s_1,s_2)\n",
    "        fw_set = fuzz.token_set_ratio(s_1,s_2)\n",
    "\n",
    "        # string lengths for each pair\n",
    "        str1_len = len(s_1)\n",
    "        str2_len = len(s_2)\n",
    "\n",
    "        # combine string metrics together and get scores from _get_dist()\n",
    "        string_metrics = [fw_ratio,fw_partial,fw_sort,fw_set,str1_len,str2_len]\n",
    "        results_.extend(string_metrics)\n",
    "        \n",
    "        # moved this up here from mean of word embeddings section\n",
    "        s1_features = s_1.split()\n",
    "        s2_features = s_2.split()\n",
    "\n",
    "        # sum of indices; proxy for word rarity\n",
    "        ##results_.append(self._index_check(s1_features))\n",
    "        ##results_.append(self._index_check(s2_features))        \n",
    "        \n",
    "        \n",
    "        # number of out-of-vocabulary and in-vocabulary items\n",
    "        #s_1_bad = sum(map(lambda word:word not in self.vocab_dict,s1_features))\n",
    "        #s_1_good = sum(map(lambda word:word in self.vocab_dict,s1_features))\n",
    "        #s_2_bad = sum(map(lambda word:word not in self.vocab_dict,s2_features))\n",
    "        #s_2_good = sum(map(lambda word:word in self.vocab_dict,s2_features))\n",
    "        #results_.append(s_1_bad)\n",
    "        #results_.append(s_1_good)\n",
    "        #results_.append(s_2_bad)\n",
    "        #results_.append(s_2_good)\n",
    "\n",
    "        # mean of word embeddings per string (0s if no items are in embeddings)\n",
    "        # shape is [1,300] per string\n",
    "        S1_ = self.embeddings[[self.vocab_dict[w] for w in s1_features if w in self.vocab_dict]]\n",
    "        S2_ = self.embeddings[[self.vocab_dict[w] for w in s2_features if w in self.vocab_dict]]\n",
    "        if S1_.shape[0]==0:\n",
    "            S1_ = np.zeros((1,300))+self.epsilon\n",
    "        if S2_.shape[0]==0:\n",
    "            S2_ = np.zeros((1,300))+self.epsilon\n",
    "        S1_ = np.asarray(np.mean(S1_,axis=0)).reshape([-1,1])\n",
    "        S2_ = np.asarray(np.mean(S2_,axis=0)).reshape([-1,1])\n",
    "        results_.extend(S1_)\n",
    "        results_.extend(S2_)\n",
    "        results_.append(cosine(S1_,S2_))\n",
    "\n",
    "        #try:\n",
    "        # fit CV on words with or without a single quote\n",
    "        vect = CountVectorizer(token_pattern='[\\w\\']+').fit([s_1, s_2])\n",
    "        features = np.asarray(vect.get_feature_names())\n",
    "\n",
    "        # get 'flow' vectors\n",
    "        v_1, v_2 = vect.transform([s_1, s_2])\n",
    "        v_1 = v_1.toarray().ravel().astype(np.float64)\n",
    "        v_2 = v_2.toarray().ravel().astype(np.float64)\n",
    "\n",
    "        # normalize vectors so as not to reward shorter strings in WMD\n",
    "        v_1 /= (v_1.sum()+self.epsilon)\n",
    "        v_2 /= (v_2.sum()+self.epsilon)\n",
    "\n",
    "        # for each out-of-vocabulary item, use the average of the 20\n",
    "        # rarest words' embeddings to represent it in the distance calc       \n",
    "        W_ = np.ndarray([0,300])\n",
    "        \n",
    "        # get distance matrix for words in both strings\n",
    "        for w in features:\n",
    "            if w in self.vocab_dict:\n",
    "                W_ = np.append(W_,self.embeddings[[self.vocab_dict[w]]],axis=0)\n",
    "            else:\n",
    "                W_ = np.append(W_,self.bad_row,axis=0)\n",
    "        \n",
    "        # use both euclidean and cosine dists (cosine dist is 1-cosine sim)\n",
    "        D_euclidean = euclidean_distances(W_).astype(np.float64)\n",
    "        D_cosine = 1.-cosine_similarity(W_,).astype(np.float64)\n",
    "\n",
    "        # using EMD (Earth Mover's Distance) from PyEMD\n",
    "        distances_euclidean = emd(v_1,v_2,D_euclidean)\n",
    "        distances_cosine = emd(v_1,v_2,D_cosine)\n",
    "\n",
    "        # both WMD calculations (euclidean and cosine)\n",
    "        results_.append(distances_euclidean)\n",
    "        results_.append(distances_cosine)\n",
    "        \n",
    "        return results_\n",
    "\n",
    "    def _data_generator(self,str_1,str_2):\n",
    "        \"\"\"\n",
    "        Transform two strings into a vector of 612 features as expected by the\n",
    "        TensorFlow model.\n",
    "        \"\"\"\n",
    "        \n",
    "        X = self._get_dist(str_1,str_2)\n",
    "\n",
    "        # X to be fed to the network\n",
    "        X = np.asarray(X).reshape((-1,609)) #612)) #12))#\"\"\"612))\"\"\"\n",
    "\n",
    "        return X\n",
    "\n",
    "    def _train_data_generator(self,shuffle,seed):\n",
    "        \"\"\"\n",
    "        Transforms self.training_set ('dataset.csv' in self.data_path) and\n",
    "        self.fuzzy_path ('fuzzy.csv' in self.data_path) into useful features\n",
    "        to train the model, and transforms error type (1 for minor,\n",
    "        2 for major) into one-hot vector of length 2 (i.e., [1,0] for minor,\n",
    "        [0,1] for major). Data are shuffled by default, as they are sorted by\n",
    "        error type in the original training sets.\n",
    "\n",
    "        Returns: X, Y, shuffled indices, original X (as pairs of strings)\n",
    "            The latter two are included purely for examining performance.\n",
    "        \"\"\"\n",
    "\n",
    "        # original training set cols are Error_type, Str_1, Str_2\n",
    "        X_in = np.genfromtxt(self.training_set,\n",
    "                      delimiter=',',usecols=(1,2),dtype=str)\n",
    "        Y_in = np.genfromtxt(self.training_set,\n",
    "                      delimiter=',',usecols=(0)).reshape((-1,1))\n",
    "\n",
    "        X = []\n",
    "        Y = []\n",
    "        bad = []\n",
    "        \n",
    "        for i,strings in enumerate(X_in):\n",
    "            try:\n",
    "                scores = self._get_dist(strings[0],strings[1])\n",
    "                X.extend(scores)\n",
    "\n",
    "                # target\n",
    "                Y.append(Y_in[i])\n",
    "            except:\n",
    "                bad.append(i)\n",
    "                continue\n",
    "        self.bad = bad\n",
    "        \n",
    "        X = np.asarray(X).reshape((-1,609))#612)) #12))#\"\"\"612))\"\"\"\n",
    "        Y = np.asarray(Y).reshape((-1,1))\n",
    "\n",
    "        # unshuffled indices\n",
    "        indices = range(X.shape[0])\n",
    "\n",
    "        # randomly shuffle the data\n",
    "        if shuffle:\n",
    "            np.random.seed(seed)\n",
    "            np.random.shuffle(indices)\n",
    "            X = X[indices]\n",
    "            Y = Y[indices]\n",
    "\n",
    "        # transform Y from either 1 or 2 to a one-hot vector ([1,0] or [0,1])\n",
    "        y_list = []\n",
    "        for i, label in enumerate(Y):\n",
    "            if label == 2:\n",
    "                label = 1\n",
    "                y_list.append(np.insert(label,0,0))\n",
    "            elif label == 1:\n",
    "                y_list.append(np.insert(label,1,0))\n",
    "            else:\n",
    "                raise ValueError(\"Y label must be either 1 (minor) or                                     2 (major). Problem at index \", indices[i])\n",
    "        Y = np.asarray(y_list)\n",
    "\n",
    "        return X,Y,indices,X_in\n",
    "\n",
    "    def _batch_norm_wrapper(self,inputs,training,decay=0.999):\n",
    "\n",
    "        scale = tf.Variable(tf.ones([inputs.get_shape()[-1]]))\n",
    "        beta = tf.Variable(tf.zeros([inputs.get_shape()[-1]]))\n",
    "        pop_mean = tf.Variable(tf.zeros([inputs.get_shape()[-1]]),\n",
    "                               trainable=False)\n",
    "        pop_var = tf.Variable(tf.ones([inputs.get_shape()[-1]]),\n",
    "                              trainable=False)\n",
    "\n",
    "        if training:\n",
    "            batch_mean,batch_var = tf.nn.moments(inputs,[0])\n",
    "            train_mean = pop_mean.assign(pop_mean*decay+batch_mean*(1-decay))\n",
    "            train_var = pop_var.assign(pop_var*decay+batch_var*(1-decay))\n",
    "            with tf.control_dependencies([train_mean,train_var]):\n",
    "                return tf.nn.batch_normalization(inputs,\n",
    "                                batch_mean,batch_var,beta,scale,self.epsilon)\n",
    "        else:\n",
    "            return tf.nn.batch_normalization(inputs,\n",
    "                            pop_mean,pop_var,beta,scale,self.epsilon)\n",
    "\n",
    "    def _build_graph(self,training):\n",
    "\n",
    "        # inputs and outputs (latter are one-hot vectors)\n",
    "        X = tf.placeholder(tf.float32, shape=[None,609])#612])#12])#\"\"\"612])\"\"\"\n",
    "        Y = tf.placeholder(tf.float32, shape=[None,2])\n",
    "        lr = tf.placeholder(tf.float32)\n",
    "        glob_step = tf.Variable(0,dtype=tf.float32,trainable=False)\n",
    "\n",
    "        weight_shape1 = [609,256]#612 #\"\"\"12\"\"\"\n",
    "        weight_shape2 = [256,128]\n",
    "        weight_shape3 = [128,16]\n",
    "        weight_shape4 = [16,2]\n",
    "\n",
    "        [n_inputs1,n_outputs1,n_inputs3,n_outputs3,n_outputs_final] =             weight_shape1[0],weight_shape1[1],weight_shape3[0],             weight_shape3[1],weight_shape4[1]\n",
    "\n",
    "        init_range1 = tf.sqrt(6.0/(n_inputs1+n_outputs1))\n",
    "        init_range2 = tf.sqrt(6.0/(n_outputs1+n_inputs3))\n",
    "        init_range3 = tf.sqrt(6.0/(n_inputs3+n_outputs3))\n",
    "        init_range4 = tf.sqrt(6.0/(n_outputs3+n_outputs_final))\n",
    "        w1 = tf.Variable(tf.random_uniform(weight_shape1,\n",
    "                                           -init_range1,init_range1),name='w1')\n",
    "        w2 = tf.Variable(tf.random_uniform(weight_shape2,\n",
    "                                           -init_range2,init_range2),name='w2')\n",
    "        w3 = tf.Variable(tf.random_uniform(weight_shape3,\n",
    "                                           -init_range3,init_range3),name='w3')\n",
    "        w4 = tf.Variable(tf.random_uniform(weight_shape4,\n",
    "                                           -init_range4,init_range4),name='w4')\n",
    "        b = tf.Variable(tf.constant(.1,shape=[n_outputs_final]))\n",
    "\n",
    "\n",
    "        # network - batch normalization in training, relu activations\n",
    "        dot1 = tf.matmul(X,w1)\n",
    "        batch_normed1 = self._batch_norm_wrapper(dot1,training)\n",
    "        rel1 = tf.nn.relu(batch_normed1)\n",
    "\n",
    "        dot2 = tf.matmul(rel1,w2)\n",
    "        batch_normed2 = self._batch_norm_wrapper(dot2,training)\n",
    "        rel2 = tf.nn.relu(batch_normed2)\n",
    "\n",
    "        dot3 = tf.matmul(rel2,w3)\n",
    "        batch_normed3 = self._batch_norm_wrapper(dot3,training)\n",
    "        rel3 = tf.nn.relu(batch_normed3)\n",
    "\n",
    "        # softmax layer\n",
    "        logits = tf.matmul(rel3,w4)+b\n",
    "        probs_x = tf.nn.softmax(logits)\n",
    "\n",
    "        # cost:\n",
    "        #    per pair\n",
    "        rows_of_cost =             tf.nn.softmax_cross_entropy_with_logits(logits,Y,\n",
    "                                                    name='rows_of_cost')\n",
    "        #    average over all pairs\n",
    "        cost = tf.reduce_mean(rows_of_cost,reduction_indices=None,\n",
    "                              keep_dims=False,name='cost')\n",
    "\n",
    "        # gradients and training\n",
    "        opt = tf.train.AdagradOptimizer(learning_rate=lr)\n",
    "        train_op = opt.minimize(cost,global_step=glob_step,\n",
    "                                var_list=[w1,w2,w3,w4,b])\n",
    "\n",
    "        # predictions and accuracy\n",
    "        correct_prediction = tf.equal(tf.arg_max(probs_x,1),tf.arg_max(Y,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "        return (X,Y),cost,train_op,accuracy,probs_x,lr,tf.train.Saver()\n",
    "\n",
    "    def train(self,shuffle=True,seed=42,validation_size=.2,test_size=.05):\n",
    "\n",
    "        \"\"\"\n",
    "        Train the model on the data stored in 'dataset.csv' in self.data_path.\n",
    "        This will check for a file named 'fuzzy.csv' first, which is the output\n",
    "        of self._get_fuzzy(), and creates it if it is not present.\n",
    "\n",
    "        Expected format of 'dataset.csv':\n",
    "            no header, three entries per row of (Error,String 1,String 2).\n",
    "            Error is an integer (1 for minor, 2 for major)\n",
    "        \"\"\"\n",
    "\n",
    "        self.training_set = os.path.join(self.data_path,'dataset.csv')\n",
    "\n",
    "        # check if data has already been split before generating and splitting\n",
    "        try:\n",
    "            assert len(self.x_train)==len(self.raw_X)-int(len(self.raw_X)*(validation_size+test_size))\n",
    "        except (AssertionError,AttributeError):\n",
    "            print(\"Generating and splitting data...\")\n",
    "            X_data,Y_data,self.shuffled_idx,self.raw_X = self._train_data_generator(shuffle,seed)\n",
    "            \n",
    "            # create split indices for validation, test, and train sets\n",
    "            self._validation_test_split_idx = int(len(Y_data)*validation_size)\n",
    "            self._train_test_split_idx = int(len(Y_data)*test_size)+self._validation_test_split_idx\n",
    "\n",
    "            # split data\n",
    "            self.x_validation = X_data[:self._validation_test_split_idx]\n",
    "            self.x_test = X_data[self._validation_test_split_idx:\n",
    "                                 self._train_test_split_idx]\n",
    "            self.x_train = X_data[self._train_test_split_idx:]\n",
    "            self.y_validation = Y_data[:self._validation_test_split_idx]\n",
    "            self.y_test = Y_data[self._validation_test_split_idx:\n",
    "                                 self._train_test_split_idx]\n",
    "            self.y_train = Y_data[self._train_test_split_idx:]\n",
    "                \n",
    "        print(\"Training model...\")\n",
    "        # build and run network in training mode\n",
    "        tf.reset_default_graph()\n",
    "        (X,Y),cost,train_op,accuracy,probs_x,lr,saver = self._build_graph(training=True)\n",
    "        \n",
    "        # just putting 0 in so first accuracy can be compared to something for now\n",
    "        self.accuracy = [0]\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.initialize_all_variables())\n",
    "            mini_batch_size = 32\n",
    "            start_end = zip(range(0,len(self.x_train),mini_batch_size),\n",
    "                           range(mini_batch_size,len(self.x_train)+1,\n",
    "                                 mini_batch_size))\n",
    "            cost_list = []\n",
    "\n",
    "            # number of training epochs\n",
    "            num_passes = 31\n",
    "            for pass_i in range(num_passes):\n",
    "                for (s,e) in start_end:\n",
    "\n",
    "                    # learning rate scheduling\n",
    "                    #if pass_i < 20:\n",
    "                    cost_list.append(sess.run(\n",
    "                            [cost],feed_dict={X:self.x_train[s:e,],\n",
    "                                              Y:self.y_train[s:e],\n",
    "                                              lr:.09}))\n",
    "                    sess.run([train_op],feed_dict={X:self.x_train[s:e,],\n",
    "                                                   Y:self.y_train[s:e],\n",
    "                                                   lr:.09})\n",
    "                    #else:\n",
    "                    #    cost_list.append(sess.run(\n",
    "                    #            [cost],feed_dict={X:self.x_train[s:e,],\n",
    "                    #                              Y:self.y_train[s:e],\n",
    "                    #                              lr:.05}))\n",
    "                    #    sess.run([train_op],feed_dict={X:self.x_train[s:e,],\n",
    "                    #                                   Y:self.y_train[s:e],\n",
    "                    #                                   lr:.05})\n",
    "                # show current accuracy\n",
    "                if pass_i % 5 == 0:\n",
    "                    result = sess.run([accuracy],\n",
    "                                      feed_dict={X:self.x_validation,\n",
    "                                                 Y:self.y_validation})\n",
    "                    print('Pass number: ',pass_i,\n",
    "                          ' -- validation set accuracy: ',result[0])\n",
    "                    \n",
    "                    # save model in self._save_path if accuracy is better than any previous run\n",
    "                    if result[0] > max(self.accuracy):\n",
    "                        save_path = saver.save(sess,self._save_path)\n",
    "                    self.accuracy.append(result[0])\n",
    "\n",
    "                    \n",
    "            # save cost and result lists for examining model performance\n",
    "            self._cost_list = cost_list\n",
    "            self._result_list = sess.run([tf.arg_max(probs_x,1)],\n",
    "                                         feed_dict={X:self.x_test,\n",
    "                                                    Y:self.y_test})\n",
    "            print(\"Model saved in file: {}\".format(save_path))\n",
    "\n",
    "    def check_results(self):\n",
    "        \"\"\"\n",
    "        Prints a confusion matrix of performance on the test set,\n",
    "        and instantiates lists of True Positive, True Negative,\n",
    "        False Positive, and False Negative for inspection as\n",
    "        self._TP, self._TN, self._FP, self._FN.\n",
    "        \"\"\"\n",
    "\n",
    "        # print confusion matrix\n",
    "        true_y_labels = np.array(self.y_test[:,1])\n",
    "        print('\\t\\tPredicted:')\n",
    "        print('\\t\\tmin. maj.')\n",
    "        print('Actual:\\t min.',\n",
    "              confusion_matrix(true_y_labels,self._result_list[0])[0])\n",
    "        print('    \\t maj.',\n",
    "              confusion_matrix(true_y_labels,self._result_list[0])[1])\n",
    "\n",
    "        # identify predicted and true positives and negatives\n",
    "        predicted_pos = np.where(self._result_list[0]==1)\n",
    "        predicted_neg = np.where(self._result_list[0]==0)\n",
    "        actual_pos = np.where(np.argmax(self.y_test,1)==1)\n",
    "        actual_neg = np.where(np.argmax(self.y_test,1)==0)\n",
    "\n",
    "        # indices of shuffled and split data (just y_test)\n",
    "        true_pos = np.intersect1d(predicted_pos,actual_pos).tolist()\n",
    "        true_neg = np.intersect1d(predicted_neg,actual_neg).tolist()\n",
    "        false_pos = np.intersect1d(predicted_pos,actual_neg).tolist()\n",
    "        false_neg = np.intersect1d(predicted_neg,actual_pos).tolist()\n",
    "        y_indices = self.shuffled_idx[self._validation_test_split_idx:\n",
    "                                      self._train_test_split_idx]\n",
    "\n",
    "        # create lists of true and false positives and negatives\n",
    "        self._TP = [list(self.raw_X[y_indices[i]]) for i in true_pos]\n",
    "        self._TN = [list(self.raw_X[y_indices[i]]) for i in true_neg]\n",
    "        self._FP = [list(self.raw_X[y_indices[i]]) for i in false_pos]\n",
    "        self._FN = [list(self.raw_X[y_indices[i]]) for i in false_neg]\n",
    "\n",
    "    def predict(self,csv_file):\n",
    "        \"\"\"\n",
    "        Predicts the type of error between the two strings in each row of\n",
    "        a CSV file.\n",
    "\n",
    "        Returns:\n",
    "            0 for minor, 1 for major,\n",
    "            'No error' for identical strings,\n",
    "            and 'Unknown' if a prediction cannot be made (could change to 0).\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        # build graph and initialize session\n",
    "        tf.reset_default_graph()\n",
    "        (X,_),_,_,_,pred_y,lr,saver = self._build_graph(training=False)\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.initialize_all_variables())\n",
    "            saver.restore(sess,self._save_path)\n",
    "\n",
    "            # generate calculations from 2d array of input strings\n",
    "            for row in np.genfromtxt(csv_file,dtype='str',delimiter=','):\n",
    "                str_1,str_2 = row[0],row[1]\n",
    "\n",
    "                # strings identical\n",
    "                if str_1 == str_2:\n",
    "                    predictions.append('No error')\n",
    "                    continue\n",
    "\n",
    "                # model prediction\n",
    "                try:\n",
    "                    pred = sess.run([tf.arg_max(pred_y,1)],\n",
    "                                    feed_dict=\\\n",
    "                                    {X: self._data_generator(str_1,str_2)})\n",
    "                    predictions.append(str(pred[0][0]+1))\n",
    "\n",
    "                # can't predict\n",
    "                except:\n",
    "                    predictions.append('Unknown')\n",
    "        \n",
    "        print(','.join(predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#GRU cell\n",
    "#mean vector back in there#\n",
    "#before/after subs\n",
    "#take out cosine to see "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '/users/rutherford/desktop/data'\n",
    "check = error_checker(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating and splitting data...\n",
      "Training model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (0,) for Tensor u'Placeholder_1:0', which has shape '(?, 2)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4eefa671687b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# is dropout really not worth putting back in?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# tanh?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcheck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-4c28f181f385>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, shuffle, seed, validation_size, test_size)\u001b[0m\n\u001b[1;32m    416\u001b[0m                     result = sess.run([accuracy],\n\u001b[1;32m    417\u001b[0m                                       feed_dict={X:self.x_validation,\n\u001b[0;32m--> 418\u001b[0;31m                                                  Y:self.y_validation})\n\u001b[0m\u001b[1;32m    419\u001b[0m                     print('Pass number: ',pass_i,\n\u001b[1;32m    420\u001b[0m                           ' -- validation set accuracy: ',result[0])\n",
      "\u001b[0;32m/Users/Rutherford/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 372\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    373\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Rutherford/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    626\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (0,) for Tensor u'Placeholder_1:0', which has shape '(?, 2)'"
     ]
    }
   ],
   "source": [
    "# wasn't breaking 73. removed 7 features. now peaks at 83 early on\n",
    "# undoing string replacements for speaker, timestamp, and digit - very slightly beter, stays above 83 whole time\n",
    "# new dataset - 91.39\n",
    "# keeping lr at .1 the whole time - 91218 at best (twice exact same)\n",
    "# adding back in rarity proxy - ALL 89268\n",
    "# taking out rarity proxy, putting back in good and bad counts -- 913058 best at 5. now lr .09 same\n",
    "# with cosine, without rarity or good/bad counts -- 913997\n",
    "\n",
    "# is dropout really not worth putting back in?\n",
    "# tanh?\n",
    "check.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,1,1,1,1,1,1,2,1,1,1,2,No error,2,1,1,1,1,1,1,2,2,1,1,1,1,1\n"
     ]
    }
   ],
   "source": [
    "check.predict(\"/Users/Rutherford/Desktop/data/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['thing', 'thong'],\n",
       "       ['chinamen', 'tiananmen'],\n",
       "       ['this is the place', ' that is her face'],\n",
       "       ['and so this', 'this'],\n",
       "       ['triumphant', 'triumph'],\n",
       "       [\"she'll\", 'should'],\n",
       "       ['006789 s1', '555943 s3'],\n",
       "       ['triumphant', 'triumvirate'],\n",
       "       ['plaintiffs', \"a plaintiff's\"],\n",
       "       ['down and', 'down or'],\n",
       "       ['sometimes', 'i think sometimes'],\n",
       "       ['word', 'org'],\n",
       "       ['fifteen miles', 'fifteen miles'],\n",
       "       ['corroborate', 'collaborate'],\n",
       "       ['cats', 'cat'],\n",
       "       ['finger', 'fingers'],\n",
       "       ['salamander', 'salamanders'],\n",
       "       ['salivate', 'salivated'],\n",
       "       ['retrieve', 'retrieved'],\n",
       "       ['emerge', 'emerging'],\n",
       "       ['think', 'thought'],\n",
       "       ['fast', 'fasted'],\n",
       "       ['brigadeer', 'brigadier'],\n",
       "       ['combuter', 'computer'],\n",
       "       ['computer', 'combuter'],\n",
       "       ['slivate', 'salivate'],\n",
       "       ['nonsneese words in pairs', 'nonsense words in pairs']], \n",
       "      dtype='|S24')"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.genfromtxt(\"/Users/Rutherford/Desktop/data/data.csv\",dtype='str',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55946, 2)"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check.y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6039"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.argmax(check.y_train,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tPredicted:\n",
      "\t\tmin. maj.\n",
      "Actual:\t min. [3222  114]\n",
      "    \t maj. [214 179]\n"
     ]
    }
   ],
   "source": [
    "check.check_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['15', 'finish paying'],\n",
       " [\"let's say\", 'and so'],\n",
       " ['you wear', \"you're wearing\"],\n",
       " [\"i don't know that's\", \"that's\"],\n",
       " [\"that's\", 'set'],\n",
       " ['myself', 'myself in these interviews'],\n",
       " [\"didn't wanna get\", 'did when i got'],\n",
       " ['no positive', 'positive'],\n",
       " ['familiarwiwith', 'familiar with this problem'],\n",
       " ['____', ''],\n",
       " ['____ staff', 'it will be staff'],\n",
       " [\"'til\", 'to'],\n",
       " ['was always', 'also'],\n",
       " ['what sit', \"what's\"],\n",
       " ['this is called', \"let's just call\"],\n",
       " [\"i'll suffer\", \"i've suffered\"],\n",
       " [\"come of those we'd be\", 'loose we were only'],\n",
       " ['this constant', \"wisconsin's\"],\n",
       " ['leukaemia and', 'leukemia and'],\n",
       " ['equity malpractices', 'equity'],\n",
       " ['please', 'jeez'],\n",
       " ['go', 'come'],\n",
       " ['fix', 'fixture'],\n",
       " [\"i'll want to\", \"it'll\"],\n",
       " ['baby fat', 'babies so i have'],\n",
       " ['how to get there', 'by looking at that'],\n",
       " ['valuable', 'valuable valuable'],\n",
       " ['pack', 'pocket'],\n",
       " ['just', 'need'],\n",
       " ['', \"what i'm saying is\"],\n",
       " ['', 'tap water laughter'],\n",
       " ['got', 'gone'],\n",
       " ['institute for physique', 'institut fur physik'],\n",
       " ['executive', 'deputy'],\n",
       " ['stated', 'said'],\n",
       " ['', 'own'],\n",
       " ['novae supernovae', 'nearby supernova'],\n",
       " ['gorgeous', 'gorgeous that there was just'],\n",
       " ['unscheduled', 'and schedule'],\n",
       " ['bring up that', \"bring i've got a\"],\n",
       " [\"we're\", \"we're great\"],\n",
       " ['mira woods', 'muir woods'],\n",
       " ['certificate', 'cert'],\n",
       " ['smaller', 'small'],\n",
       " ['a ____', 'another'],\n",
       " ['just i think', 'just starting'],\n",
       " ['content is', 'front end'],\n",
       " ['current intuitively', 'counter-intuitively'],\n",
       " ['', \"i don't use r\"],\n",
       " ['rebuilds', 're bills'],\n",
       " ['', 'hit'],\n",
       " [\"i've seen\", \"i'm seeing\"],\n",
       " ['', 'able'],\n",
       " ['insurance it would', 'insurance it will'],\n",
       " ['shows this', \"elizabeth's\"],\n",
       " ['yeah ____', \"yeah what's the flip side\"],\n",
       " ['we pay', 'you get paid'],\n",
       " ['projects', 'projects feel like'],\n",
       " ['thousands', 'dozens'],\n",
       " ['website', 'web side'],\n",
       " [\"we're talking\", 'we talked'],\n",
       " ['____', \"haven't\"],\n",
       " ['vpis', 'the pis'],\n",
       " ['thought he was', \"think he's\"],\n",
       " ['the staff', 'this death'],\n",
       " ['two bigger companies that', 'too big a company to'],\n",
       " ['60', '60 miles'],\n",
       " ['siblings', 'siblings and whatnot'],\n",
       " ['', 'brilliant'],\n",
       " ['band no one', 'band but nobody'],\n",
       " ['as what sam', 'so as roxanne'],\n",
       " ['rag', 'right'],\n",
       " ['event', 'of an'],\n",
       " ['back to', 'about'],\n",
       " ['and i wrote for', 'for'],\n",
       " ['always', 'with'],\n",
       " ['employed', 'an employee'],\n",
       " ['joke', 'joke or joking with me'],\n",
       " [\"happenstance there's\", \"happens to us there's\"],\n",
       " ['____', 'exists'],\n",
       " ['suffer', '____'],\n",
       " ['also', \"god's\"],\n",
       " ['', 'property'],\n",
       " ['we get', \"we've got\"],\n",
       " ['temple sight', 'temple site'],\n",
       " ['in my offer was', 'am i off was'],\n",
       " ['stand', \"you don't have to stand\"],\n",
       " ['they seen', \"they're seeing\"],\n",
       " ['during one year', 'during when they were'],\n",
       " ['deits', 'deets'],\n",
       " ['never pondered', 'ever pondered'],\n",
       " ['us', 'us8'],\n",
       " ['go to', 'with their'],\n",
       " [\"i'd ____ to say\", 'i read an article on there'],\n",
       " ['has says', 'this has'],\n",
       " ['woo-hi that', 'uhai'],\n",
       " ['got on', 'go out'],\n",
       " ['it', \"it it's a tough one\"],\n",
       " ['non-profit use', 'non-profity'],\n",
       " ['equire', 'geekwire'],\n",
       " ['mismatched', 'mismashed'],\n",
       " ['although', 'though'],\n",
       " ['17', '17 when you joined'],\n",
       " ['contacts', 'contracts'],\n",
       " ['____ probably', 'probably they'],\n",
       " ['sort of', 'be'],\n",
       " ['we know nothing better i guess', \"you don't\"],\n",
       " ['remind', 'a minor cold'],\n",
       " ['fine to write', 'find the right'],\n",
       " ['the fact of altruists though', 'effective altruists though'],\n",
       " ['things', 'well so the policy would be things'],\n",
       " ['name ecollegehavardedu', 'name at collegehavardedu'],\n",
       " ['rap', 'rupp'],\n",
       " ['lunch', 'large'],\n",
       " ['them outside', 'them i would say'],\n",
       " ['college does', 'city college does'],\n",
       " ['usually', \"'cause usually\"],\n",
       " ['stoats', 'stoics'],\n",
       " ['wanted', 'tried'],\n",
       " ['', 'xp'],\n",
       " ['leading', 'leaning'],\n",
       " ['them', 'stuff'],\n",
       " ['all the', 'a lot of'],\n",
       " ['site it was too', \"site it's really\"],\n",
       " ['customer answers', 'customers a sense of'],\n",
       " ['house', 'house you mean'],\n",
       " [\"'cause of amenities\", 'for the amenities'],\n",
       " ['the stuff', 'just something'],\n",
       " ['a', 'per'],\n",
       " ['when the', 'another'],\n",
       " ['ahead', 'there'],\n",
       " ['pfew', 'phew'],\n",
       " ['college is just', 'colleges are'],\n",
       " ['one to an', 'one-two on'],\n",
       " ['rome', 'roman'],\n",
       " ['them they', 'them may'],\n",
       " ['tafu', 'tafe'],\n",
       " ['without', 'without 029530 s1 good legal term 029558 s2'],\n",
       " ['actually', 'anyway'],\n",
       " ['', 'tend to'],\n",
       " ['well', 'welch'],\n",
       " ['a lot of the studies', 'the studies yeah'],\n",
       " ['not dilemma and', 'that dilemma and'],\n",
       " ['federal legislations supersede', 'federal legislation supercede'],\n",
       " ['extra gaming', 'exergaming'],\n",
       " ['good', 'go'],\n",
       " [\"we're on\", 'we run'],\n",
       " ['given the idea', 'to give an idea'],\n",
       " ['wonder', 'wander'],\n",
       " ['', 'no regulation there'],\n",
       " ['to', 'no'],\n",
       " ['', 'my incentive is'],\n",
       " [\"access that's\", \"access site there's\"],\n",
       " ['detachment pronunciation', 'detachment renunciation'],\n",
       " ['sides', 'asides'],\n",
       " ['world it will', \"role it'll\"],\n",
       " ['also', 'also if it takes'],\n",
       " ['this', 'this decision'],\n",
       " ['point list of', 'list'],\n",
       " ['yeah', 'yeah it depends'],\n",
       " ['metabolised', 'metabolized'],\n",
       " [\"us that's where\", \"us as we're\"],\n",
       " ['the steak-holder', \"they're steakholders\"],\n",
       " ['at', 'against'],\n",
       " [\"we're gonna\", 'we now really'],\n",
       " ['all', 'how will'],\n",
       " ['snyder', 'schneider'],\n",
       " ['might claim', \"i'm not blaming\"],\n",
       " ['my health', 'myself'],\n",
       " ['emigrate', 'immigrate'],\n",
       " ['', 'brought'],\n",
       " ['recalled case', 'rico case'],\n",
       " ['we sent', \"we'll say\"],\n",
       " [\"you're taking\", \"you've taken\"],\n",
       " ['first what', 'first time going what'],\n",
       " ['cell types the cell', 'subtypes b cell'],\n",
       " [\"else' feelings\", \"else's feelings 038502 s1 oh okay 038536 s2\"],\n",
       " ['give a new', \"i've given you\"],\n",
       " ['', 'xerox'],\n",
       " ['prospective', 'perspective'],\n",
       " [\"that's kind of weird you know yeah\", \"i'm just kinda weird\"],\n",
       " ['click pick', 'click click'],\n",
       " ['i feel for', 'for'],\n",
       " ['', 'done'],\n",
       " ['you can see', 'at unc'],\n",
       " ['to help', 'the health'],\n",
       " ['', 'just real quick'],\n",
       " ['day it makes', 'time so'],\n",
       " ['jermaine', 'jamir'],\n",
       " ['knight', 'neidorff yeah'],\n",
       " ['watson', 'the way it works'],\n",
       " ['', \"okay i'll make this up 032010 s1\"],\n",
       " ['stuff', 'assessments'],\n",
       " ['client is staying', \"client's gonna stay\"],\n",
       " ['giving', 'gonna give'],\n",
       " ['put no', 'put a note'],\n",
       " ['look at this', 'know what that is'],\n",
       " ['some', 'somewhat of a'],\n",
       " [\"if you're\", 'here'],\n",
       " ['columbian', 'colombian'],\n",
       " ['giving 07255 s', 'giving'],\n",
       " [\"one that's stem is\", \"the one that debb's\"],\n",
       " ['colonia heights', 'colonial heights'],\n",
       " ['____', 'se'],\n",
       " ['71000-some-odd', '71000-some-odd dollars'],\n",
       " ['yeah', 'yeah just when i was there'],\n",
       " ['re-stratified patient specific', 'risk-stratified patient-specific'],\n",
       " ['junior', 'ju'],\n",
       " [\"you're\", \"you're starting\"],\n",
       " [\"we've\", 'group'],\n",
       " [\"that's what i am saying ____\", \"it's like just do it\"],\n",
       " ['should', 'oughta'],\n",
       " ['', \"and make sure it's going yep great\"],\n",
       " ['round', 'around']]"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check._FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s_1 = \"help a man with 2 tricks\"\n",
    "s_2 = \"had the pan kick you figs\"\n",
    "s1_features = s_1.split()\n",
    "s2_features = s_2.split()\n",
    "S1_ = check.embeddings[[check.vocab_dict[w] for w in s1_features if w in check.vocab_dict]]\n",
    "S2_ = check.embeddings[[check.vocab_dict[w] for w in s2_features if w in check.vocab_dict]]\n",
    "if S1_.shape[0]==0:\n",
    "    S1_ = np.ones((1,300))\n",
    "if S2_.shape[0]==0:\n",
    "    S2_ = np.ones((1,300))\n",
    "S1_ = np.asarray(np.mean(S1_,axis=0)).reshape([-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1171875 ],\n",
       "       [ 0.02016602],\n",
       "       [ 0.03173828],\n",
       "       [ 0.06984863],\n",
       "       [-0.09223633],\n",
       "       [ 0.02331696],\n",
       "       [-0.08835449],\n",
       "       [-0.03043213],\n",
       "       [ 0.01704102],\n",
       "       [ 0.00200043],\n",
       "       [-0.01826172],\n",
       "       [-0.13187256],\n",
       "       [-0.01455078],\n",
       "       [-0.02015381],\n",
       "       [-0.09570312],\n",
       "       [ 0.04291992],\n",
       "       [-0.03383789],\n",
       "       [ 0.07277832],\n",
       "       [-0.01466064],\n",
       "       [-0.06610718],\n",
       "       [-0.02854004],\n",
       "       [-0.01780701],\n",
       "       [ 0.08985596],\n",
       "       [-0.07788086],\n",
       "       [ 0.03791504],\n",
       "       [-0.03056641],\n",
       "       [-0.14462891],\n",
       "       [ 0.08963623],\n",
       "       [ 0.06392822],\n",
       "       [-0.01276855],\n",
       "       [-0.00561523],\n",
       "       [ 0.00458984],\n",
       "       [-0.06914062],\n",
       "       [-0.13850098],\n",
       "       [-0.10505371],\n",
       "       [ 0.08625488],\n",
       "       [ 0.05874023],\n",
       "       [ 0.04329224],\n",
       "       [ 0.12088623],\n",
       "       [ 0.14986572],\n",
       "       [ 0.0517334 ],\n",
       "       [ 0.00634766],\n",
       "       [ 0.03461914],\n",
       "       [ 0.0427124 ],\n",
       "       [ 0.0179657 ],\n",
       "       [-0.09044189],\n",
       "       [ 0.02324219],\n",
       "       [-0.06833496],\n",
       "       [ 0.02122803],\n",
       "       [ 0.1163208 ],\n",
       "       [-0.09169922],\n",
       "       [ 0.08562012],\n",
       "       [ 0.01955566],\n",
       "       [-0.07939453],\n",
       "       [ 0.02080078],\n",
       "       [-0.04960937],\n",
       "       [-0.09960938],\n",
       "       [-0.07663574],\n",
       "       [ 0.01816406],\n",
       "       [-0.04378662],\n",
       "       [ 0.0211792 ],\n",
       "       [ 0.10327148],\n",
       "       [-0.14213867],\n",
       "       [-0.04501953],\n",
       "       [ 0.00703125],\n",
       "       [-0.01265259],\n",
       "       [-0.03659668],\n",
       "       [ 0.04985352],\n",
       "       [ 0.01209412],\n",
       "       [ 0.07475586],\n",
       "       [ 0.06320801],\n",
       "       [ 0.08522339],\n",
       "       [-0.05402832],\n",
       "       [ 0.03295288],\n",
       "       [-0.06323242],\n",
       "       [ 0.01171875],\n",
       "       [ 0.01378174],\n",
       "       [ 0.02314453],\n",
       "       [-0.01507568],\n",
       "       [ 0.01142578],\n",
       "       [-0.04714355],\n",
       "       [-0.02392578],\n",
       "       [-0.02771606],\n",
       "       [-0.06461182],\n",
       "       [-0.08408203],\n",
       "       [ 0.01201172],\n",
       "       [-0.15991211],\n",
       "       [ 0.00910645],\n",
       "       [ 0.07763672],\n",
       "       [-0.02954102],\n",
       "       [-0.04187012],\n",
       "       [ 0.13100586],\n",
       "       [ 0.02145996],\n",
       "       [-0.04919434],\n",
       "       [ 0.06225586],\n",
       "       [-0.07650757],\n",
       "       [ 0.02177734],\n",
       "       [ 0.01357422],\n",
       "       [ 0.01862793],\n",
       "       [ 0.02919922],\n",
       "       [ 0.03115234],\n",
       "       [-0.10966797],\n",
       "       [ 0.02280273],\n",
       "       [-0.05756836],\n",
       "       [ 0.14414062],\n",
       "       [-0.06096191],\n",
       "       [ 0.03891602],\n",
       "       [-0.0423481 ],\n",
       "       [ 0.05373535],\n",
       "       [-0.1275177 ],\n",
       "       [-0.10091553],\n",
       "       [-0.03510742],\n",
       "       [-0.02507324],\n",
       "       [-0.04538574],\n",
       "       [-0.00739441],\n",
       "       [ 0.11633301],\n",
       "       [ 0.05898437],\n",
       "       [ 0.01494141],\n",
       "       [ 0.0522644 ],\n",
       "       [ 0.10107422],\n",
       "       [-0.02502441],\n",
       "       [ 0.01259766],\n",
       "       [-0.10654297],\n",
       "       [-0.06799316],\n",
       "       [ 0.00600586],\n",
       "       [-0.09941406],\n",
       "       [-0.03359985],\n",
       "       [-0.01242676],\n",
       "       [ 0.15068359],\n",
       "       [ 0.04916992],\n",
       "       [-0.03735352],\n",
       "       [-0.1041748 ],\n",
       "       [-0.04190674],\n",
       "       [ 0.08035889],\n",
       "       [-0.13032227],\n",
       "       [ 0.04813232],\n",
       "       [ 0.02408447],\n",
       "       [ 0.01894531],\n",
       "       [ 0.03569336],\n",
       "       [ 0.08012695],\n",
       "       [ 0.11320801],\n",
       "       [ 0.01083984],\n",
       "       [ 0.05742187],\n",
       "       [ 0.00561523],\n",
       "       [-0.00195312],\n",
       "       [ 0.02724609],\n",
       "       [-0.05465088],\n",
       "       [-0.07949219],\n",
       "       [-0.03402405],\n",
       "       [-0.01053467],\n",
       "       [ 0.17011871],\n",
       "       [-0.02636719],\n",
       "       [-0.14561768],\n",
       "       [ 0.01416016],\n",
       "       [ 0.01882324],\n",
       "       [ 0.07861328],\n",
       "       [-0.09833984],\n",
       "       [-0.06259766],\n",
       "       [-0.08510742],\n",
       "       [-0.01660156],\n",
       "       [-0.0182251 ],\n",
       "       [ 0.02485352],\n",
       "       [ 0.10888672],\n",
       "       [ 0.03481445],\n",
       "       [ 0.0010498 ],\n",
       "       [-0.09960938],\n",
       "       [ 0.10722656],\n",
       "       [-0.00512695],\n",
       "       [-0.07111816],\n",
       "       [-0.01304932],\n",
       "       [-0.0385437 ],\n",
       "       [-0.03477783],\n",
       "       [-0.0097168 ],\n",
       "       [-0.05073242],\n",
       "       [-0.10488281],\n",
       "       [-0.07398682],\n",
       "       [ 0.08994751],\n",
       "       [-0.04863281],\n",
       "       [-0.12783203],\n",
       "       [ 0.01206055],\n",
       "       [-0.01691895],\n",
       "       [-0.06453857],\n",
       "       [ 0.04716797],\n",
       "       [ 0.04985352],\n",
       "       [-0.17114258],\n",
       "       [ 0.01699219],\n",
       "       [ 0.01166992],\n",
       "       [-0.009375  ],\n",
       "       [ 0.15791016],\n",
       "       [-0.07802734],\n",
       "       [ 0.06768951],\n",
       "       [-0.00180664],\n",
       "       [ 0.03046875],\n",
       "       [-0.06494141],\n",
       "       [ 0.00734863],\n",
       "       [-0.00773926],\n",
       "       [-0.04741211],\n",
       "       [-0.00768433],\n",
       "       [-0.14282227],\n",
       "       [-0.17441406],\n",
       "       [-0.0831543 ],\n",
       "       [ 0.0527832 ],\n",
       "       [-0.05102539],\n",
       "       [-0.03693848],\n",
       "       [-0.0135376 ],\n",
       "       [-0.02937622],\n",
       "       [-0.07270508],\n",
       "       [-0.02080078],\n",
       "       [-0.07512207],\n",
       "       [-0.05797119],\n",
       "       [-0.04750977],\n",
       "       [ 0.02446289],\n",
       "       [-0.02248535],\n",
       "       [ 0.02983398],\n",
       "       [-0.02958984],\n",
       "       [-0.02223816],\n",
       "       [ 0.07124023],\n",
       "       [ 0.05703125],\n",
       "       [-0.14125977],\n",
       "       [-0.00148926],\n",
       "       [-0.06939087],\n",
       "       [-0.02111816],\n",
       "       [ 0.04707031],\n",
       "       [-0.03571167],\n",
       "       [ 0.01210938],\n",
       "       [-0.01364746],\n",
       "       [-0.03429871],\n",
       "       [-0.0145752 ],\n",
       "       [ 0.01328735],\n",
       "       [-0.11467285],\n",
       "       [ 0.06398926],\n",
       "       [-0.05354004],\n",
       "       [-0.01156006],\n",
       "       [ 0.06152344],\n",
       "       [ 0.01799316],\n",
       "       [-0.04006348],\n",
       "       [ 0.00067139],\n",
       "       [-0.03253632],\n",
       "       [ 0.03121338],\n",
       "       [ 0.02196045],\n",
       "       [-0.01650391],\n",
       "       [ 0.13088379],\n",
       "       [-0.02723999],\n",
       "       [-0.00810547],\n",
       "       [ 0.04667969],\n",
       "       [ 0.00693359],\n",
       "       [ 0.05654297],\n",
       "       [ 0.13300781],\n",
       "       [ 0.03579102],\n",
       "       [-0.04067383],\n",
       "       [ 0.07138062],\n",
       "       [ 0.02109375],\n",
       "       [ 0.02783203],\n",
       "       [ 0.12653503],\n",
       "       [ 0.06518555],\n",
       "       [-0.01130981],\n",
       "       [ 0.03520508],\n",
       "       [-0.09179688],\n",
       "       [-0.06981201],\n",
       "       [-0.00119629],\n",
       "       [-0.02324219],\n",
       "       [-0.01064453],\n",
       "       [-0.06079102],\n",
       "       [ 0.04995117],\n",
       "       [-0.01628418],\n",
       "       [ 0.14628906],\n",
       "       [-0.01807861],\n",
       "       [ 0.06401367],\n",
       "       [-0.1078125 ],\n",
       "       [ 0.01083984],\n",
       "       [ 0.00922852],\n",
       "       [ 0.07344971],\n",
       "       [ 0.03442383],\n",
       "       [-0.02226563],\n",
       "       [ 0.11263428],\n",
       "       [ 0.06237793],\n",
       "       [-0.04451904],\n",
       "       [-0.01459961],\n",
       "       [-0.07207031],\n",
       "       [ 0.03926086],\n",
       "       [ 0.06025391],\n",
       "       [-0.05976563],\n",
       "       [ 0.03916016],\n",
       "       [ 0.20576172],\n",
       "       [ 0.00209961],\n",
       "       [-0.01467285],\n",
       "       [-0.0845459 ],\n",
       "       [-0.07119141],\n",
       "       [ 0.01347656],\n",
       "       [ 0.00406494],\n",
       "       [ 0.01386719],\n",
       "       [ 0.0427063 ],\n",
       "       [-0.1329834 ],\n",
       "       [-0.03876953],\n",
       "       [-0.06295166],\n",
       "       [-0.01210938],\n",
       "       [-0.06958008],\n",
       "       [-0.07713623],\n",
       "       [-0.09902344],\n",
       "       [ 0.01831055]])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.asarray(np.mean(S2_,axis=0)).reshape([-1,1])\n",
    "S1_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29,\n",
       " 33,\n",
       " 29,\n",
       " 29,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0.86971835432000122,\n",
       " 2.592264513858284,\n",
       " 0.8696313911808831]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check._get_dist('help','had')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tPredicted:\n",
      "\t\tmin. maj.\n",
      "Actual:\t min. [2564  260]\n",
      "    \t maj. [409 692]\n"
     ]
    }
   ],
   "source": [
    "# 81 with normal stuff\n",
    "# 80.79 but bad with 10% val, 5% test\n",
    "# 81 with 35% val, 5% test\n",
    "# 80.6 more FN than TP with 65% val, 5% test\n",
    "# 82.9 with cleaned set and 25% 5%\n",
    "# 83.0 AT PASS 15 (827) with numbers and dashes gone\n",
    "# 83.1 AT PASS 20 (8288) everything in get_dist\n",
    "# all fillers and metas and re.subs --- no 824 or so\n",
    "check.check_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[89,\n",
       " 89,\n",
       " 89,\n",
       " 89,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0.018310546875,\n",
       " -0.1181640625,\n",
       " 0.040283203125,\n",
       " 0.35546875,\n",
       " 0.1533203125,\n",
       " -0.2021484375,\n",
       " -0.051513671875,\n",
       " 0.259765625,\n",
       " 0.00958251953125,\n",
       " 0.2392578125,\n",
       " 0.06396484375,\n",
       " 0.1025390625,\n",
       " -0.07177734375,\n",
       " 0.0142822265625,\n",
       " -0.07080078125,\n",
       " 0.244140625,\n",
       " 0.1650390625,\n",
       " 0.3984375,\n",
       " -0.0037994384765625,\n",
       " -0.08935546875,\n",
       " 0.0458984375,\n",
       " -0.0252685546875,\n",
       " 0.07373046875,\n",
       " 0.0220947265625,\n",
       " 0.216796875,\n",
       " -0.01507568359375,\n",
       " -0.09716796875,\n",
       " 0.01806640625,\n",
       " 0.016845703125,\n",
       " 0.033935546875,\n",
       " -0.1328125,\n",
       " -0.1337890625,\n",
       " 0.01171875,\n",
       " -0.275390625,\n",
       " -0.032958984375,\n",
       " -0.01275634765625,\n",
       " 0.236328125,\n",
       " 0.263671875,\n",
       " 0.0147705078125,\n",
       " 0.11328125,\n",
       " -0.044677734375,\n",
       " 0.0030975341796875,\n",
       " 0.036376953125,\n",
       " -0.130859375,\n",
       " -0.21484375,\n",
       " -0.240234375,\n",
       " -0.10888671875,\n",
       " 0.08740234375,\n",
       " 0.00052642822265625,\n",
       " 0.007293701171875,\n",
       " -0.07958984375,\n",
       " -0.2333984375,\n",
       " -0.0498046875,\n",
       " 0.236328125,\n",
       " -0.0113525390625,\n",
       " -0.302734375,\n",
       " -0.001129150390625,\n",
       " -0.07861328125,\n",
       " -0.447265625,\n",
       " 0.02099609375,\n",
       " -0.0208740234375,\n",
       " 0.0108642578125,\n",
       " -0.412109375,\n",
       " -0.11865234375,\n",
       " -0.130859375,\n",
       " 0.142578125,\n",
       " -0.126953125,\n",
       " -0.0194091796875,\n",
       " 0.201171875,\n",
       " 0.2294921875,\n",
       " -0.671875,\n",
       " 0.11572265625,\n",
       " 0.337890625,\n",
       " -0.1572265625,\n",
       " 0.07470703125,\n",
       " 0.00799560546875,\n",
       " -0.04345703125,\n",
       " 0.1455078125,\n",
       " -0.04296875,\n",
       " 0.10595703125,\n",
       " -0.11572265625,\n",
       " -0.0284423828125,\n",
       " -0.2099609375,\n",
       " -0.03271484375,\n",
       " -0.04345703125,\n",
       " 0.038818359375,\n",
       " -0.169921875,\n",
       " 0.1328125,\n",
       " 0.07861328125,\n",
       " -0.19140625,\n",
       " -0.029296875,\n",
       " -0.40234375,\n",
       " -0.1865234375,\n",
       " -0.06103515625,\n",
       " 0.173828125,\n",
       " -0.11669921875,\n",
       " 0.203125,\n",
       " -0.02001953125,\n",
       " 0.357421875,\n",
       " -0.26171875,\n",
       " -0.1767578125,\n",
       " -0.578125,\n",
       " -0.031494140625,\n",
       " 0.01324462890625,\n",
       " 0.05419921875,\n",
       " -0.37890625,\n",
       " 0.18359375,\n",
       " 0.15234375,\n",
       " 0.2373046875,\n",
       " -0.3125,\n",
       " 0.001190185546875,\n",
       " 0.1015625,\n",
       " -0.1484375,\n",
       " -0.10302734375,\n",
       " -0.0084228515625,\n",
       " -0.09716796875,\n",
       " 0.462890625,\n",
       " -0.076171875,\n",
       " 0.2734375,\n",
       " 0.232421875,\n",
       " 0.043212890625,\n",
       " 0.1494140625,\n",
       " -0.17578125,\n",
       " 0.10791015625,\n",
       " 0.408203125,\n",
       " -0.166015625,\n",
       " -0.1240234375,\n",
       " -0.390625,\n",
       " -0.140625,\n",
       " -0.020751953125,\n",
       " -0.296875,\n",
       " -0.07568359375,\n",
       " -0.0260009765625,\n",
       " -0.2353515625,\n",
       " -0.337890625,\n",
       " -0.1884765625,\n",
       " -0.27734375,\n",
       " -0.01165771484375,\n",
       " 0.07763671875,\n",
       " -0.1142578125,\n",
       " 0.03076171875,\n",
       " -0.080078125,\n",
       " -0.03271484375,\n",
       " 0.083984375,\n",
       " -0.19921875,\n",
       " -0.01458740234375,\n",
       " 0.0244140625,\n",
       " 0.234375,\n",
       " 0.00860595703125,\n",
       " 0.2294921875,\n",
       " 0.2734375,\n",
       " -0.134765625,\n",
       " -0.2099609375,\n",
       " -0.06494140625,\n",
       " 0.140625,\n",
       " 0.146484375,\n",
       " -0.00482177734375,\n",
       " -0.359375,\n",
       " -0.09423828125,\n",
       " -0.125,\n",
       " 0.057373046875,\n",
       " 0.045166015625,\n",
       " 0.07666015625,\n",
       " -0.283203125,\n",
       " -0.0240478515625,\n",
       " -0.11767578125,\n",
       " -0.1396484375,\n",
       " -0.06396484375,\n",
       " 0.033935546875,\n",
       " 0.10986328125,\n",
       " 0.1357421875,\n",
       " 0.2021484375,\n",
       " -0.28515625,\n",
       " 0.0093994140625,\n",
       " -0.09619140625,\n",
       " 0.1259765625,\n",
       " 0.04345703125,\n",
       " 0.1455078125,\n",
       " -0.107421875,\n",
       " -0.0206298828125,\n",
       " -0.26171875,\n",
       " 0.119140625,\n",
       " -0.10205078125,\n",
       " -0.28125,\n",
       " -0.224609375,\n",
       " 0.150390625,\n",
       " -0.2138671875,\n",
       " 0.279296875,\n",
       " 0.2099609375,\n",
       " -0.022216796875,\n",
       " -0.41796875,\n",
       " 0.07177734375,\n",
       " -0.049072265625,\n",
       " -0.11474609375,\n",
       " -0.0245361328125,\n",
       " -0.006072998046875,\n",
       " -0.1025390625,\n",
       " 0.08349609375,\n",
       " -0.04931640625,\n",
       " -0.248046875,\n",
       " -0.072265625,\n",
       " 0.00457763671875,\n",
       " 0.06884765625,\n",
       " 0.020751953125,\n",
       " -0.2158203125,\n",
       " -0.06201171875,\n",
       " -0.032958984375,\n",
       " -0.1611328125,\n",
       " 0.1904296875,\n",
       " -0.003204345703125,\n",
       " 0.1669921875,\n",
       " -0.1259765625,\n",
       " -0.0634765625,\n",
       " 0.16015625,\n",
       " -0.0810546875,\n",
       " 0.11083984375,\n",
       " 0.017578125,\n",
       " 0.02099609375,\n",
       " -0.2080078125,\n",
       " 0.2216796875,\n",
       " 0.0086669921875,\n",
       " -0.197265625,\n",
       " 0.06689453125,\n",
       " -0.2109375,\n",
       " -0.087890625,\n",
       " -0.23828125,\n",
       " 0.171875,\n",
       " -0.005584716796875,\n",
       " -0.333984375,\n",
       " -0.20703125,\n",
       " -0.123046875,\n",
       " 0.091796875,\n",
       " 0.11767578125,\n",
       " 0.076171875,\n",
       " 0.0206298828125,\n",
       " -0.234375,\n",
       " 0.11865234375,\n",
       " -0.09033203125,\n",
       " -0.244140625,\n",
       " -0.0634765625,\n",
       " -0.115234375,\n",
       " -0.0050048828125,\n",
       " 0.166015625,\n",
       " -0.1435546875,\n",
       " 0.2041015625,\n",
       " 0.034912109375,\n",
       " -0.2109375,\n",
       " 0.22265625,\n",
       " -0.31640625,\n",
       " -0.3046875,\n",
       " -0.1796875,\n",
       " -0.2109375,\n",
       " -0.048583984375,\n",
       " -0.1416015625,\n",
       " -0.306640625,\n",
       " -0.072265625,\n",
       " 0.09814453125,\n",
       " 0.1376953125,\n",
       " -0.0712890625,\n",
       " 0.484375,\n",
       " -0.0037078857421875,\n",
       " -0.140625,\n",
       " -0.1416015625,\n",
       " 0.2353515625,\n",
       " -0.1630859375,\n",
       " -0.024169921875,\n",
       " -0.1630859375,\n",
       " -0.0556640625,\n",
       " -0.18359375,\n",
       " 0.15234375,\n",
       " -0.056640625,\n",
       " 0.2109375,\n",
       " 0.1376953125,\n",
       " 0.275390625,\n",
       " -0.2392578125,\n",
       " 0.053466796875,\n",
       " 0.1826171875,\n",
       " 0.0478515625,\n",
       " 0.197265625,\n",
       " 0.01263427734375,\n",
       " -0.341796875,\n",
       " -0.349609375,\n",
       " -0.07666015625,\n",
       " -0.044921875,\n",
       " -0.060302734375,\n",
       " -0.15625,\n",
       " 0.09619140625,\n",
       " -0.1162109375,\n",
       " 0.2353515625,\n",
       " 0.14453125,\n",
       " -0.022705078125,\n",
       " 0.040283203125,\n",
       " 0.0079345703125,\n",
       " 0.10693359375,\n",
       " 0.10205078125,\n",
       " 0.03662109375,\n",
       " 0.2138671875,\n",
       " 0.0595703125,\n",
       " -0.01519775390625,\n",
       " -0.037109375,\n",
       " -0.035888671875,\n",
       " -0.20703125,\n",
       " -0.039306640625,\n",
       " 0.3359375,\n",
       " 0.095703125,\n",
       " -0.11767578125,\n",
       " -0.02978515625,\n",
       " 0.08544921875,\n",
       " 0.09912109375,\n",
       " 0.125,\n",
       " -0.034423828125,\n",
       " -0.0595703125,\n",
       " -0.03759765625,\n",
       " -0.08740234375,\n",
       " -0.05419921875,\n",
       " 0.056396484375,\n",
       " -0.07861328125,\n",
       " 0.003936767578125,\n",
       " -0.05517578125,\n",
       " 0.353515625,\n",
       " -0.029296875,\n",
       " -0.1904296875,\n",
       " 0.10693359375,\n",
       " -0.1435546875,\n",
       " 0.1689453125,\n",
       " 0.046142578125,\n",
       " -0.28515625,\n",
       " -0.0771484375,\n",
       " -0.05712890625,\n",
       " -0.2431640625,\n",
       " 0.1201171875,\n",
       " -0.2890625,\n",
       " -0.2060546875,\n",
       " 0.0888671875,\n",
       " 0.0654296875,\n",
       " -0.11962890625,\n",
       " 0.1220703125,\n",
       " 0.037109375,\n",
       " -0.20703125,\n",
       " -0.009765625,\n",
       " 0.0869140625,\n",
       " -0.1357421875,\n",
       " -0.048583984375,\n",
       " -0.193359375,\n",
       " -0.18359375,\n",
       " -0.1796875,\n",
       " -0.189453125,\n",
       " -0.072265625,\n",
       " -0.1103515625,\n",
       " 0.078125,\n",
       " -0.044921875,\n",
       " -0.171875,\n",
       " 0.1923828125,\n",
       " 0.2294921875,\n",
       " 0.0732421875,\n",
       " -0.057373046875,\n",
       " -0.01483154296875,\n",
       " -0.055419921875,\n",
       " -0.150390625,\n",
       " 0.02294921875,\n",
       " 0.057861328125,\n",
       " 0.2353515625,\n",
       " -0.345703125,\n",
       " 0.01226806640625,\n",
       " 0.0517578125,\n",
       " 0.01153564453125,\n",
       " 0.059326171875,\n",
       " 0.20703125,\n",
       " 0.17578125,\n",
       " 0.05908203125,\n",
       " -0.23828125,\n",
       " -0.060302734375,\n",
       " 0.10791015625,\n",
       " -0.0301513671875,\n",
       " 0.08984375,\n",
       " -0.04541015625,\n",
       " 0.0145263671875,\n",
       " -0.00396728515625,\n",
       " -0.061279296875,\n",
       " -0.1083984375,\n",
       " 0.07568359375,\n",
       " -0.1455078125,\n",
       " -0.034423828125,\n",
       " 0.27734375,\n",
       " -0.2265625,\n",
       " 0.01043701171875,\n",
       " -0.0673828125,\n",
       " 0.13671875,\n",
       " 0.0103759765625,\n",
       " 0.000896453857421875,\n",
       " 0.08837890625,\n",
       " -0.12451171875,\n",
       " -0.0908203125,\n",
       " 0.08251953125,\n",
       " -0.00732421875,\n",
       " -0.0380859375,\n",
       " -0.0751953125,\n",
       " 0.004669189453125,\n",
       " 0.263671875,\n",
       " -0.07666015625,\n",
       " -0.09716796875,\n",
       " -0.490234375,\n",
       " -0.189453125,\n",
       " 0.2060546875,\n",
       " 0.126953125,\n",
       " -0.345703125,\n",
       " 0.0947265625,\n",
       " 0.051025390625,\n",
       " 0.07080078125,\n",
       " -0.1640625,\n",
       " -0.10693359375,\n",
       " -0.09033203125,\n",
       " -0.1376953125,\n",
       " -0.2470703125,\n",
       " -0.04833984375,\n",
       " 0.0869140625,\n",
       " 0.2431640625,\n",
       " -0.09423828125,\n",
       " 0.2041015625,\n",
       " 0.0498046875,\n",
       " -0.2314453125,\n",
       " 0.09765625,\n",
       " -0.2294921875,\n",
       " 0.0007781982421875,\n",
       " 0.3125,\n",
       " -0.022216796875,\n",
       " -0.06982421875,\n",
       " -0.1318359375,\n",
       " 0.0306396484375,\n",
       " 0.10791015625,\n",
       " -0.37109375,\n",
       " -0.169921875,\n",
       " 0.09521484375,\n",
       " -0.263671875,\n",
       " 0.0439453125,\n",
       " -0.130859375,\n",
       " -0.29296875,\n",
       " -0.00946044921875,\n",
       " 0.01495361328125,\n",
       " -0.1357421875,\n",
       " 0.06689453125,\n",
       " -0.2431640625,\n",
       " 0.126953125,\n",
       " 0.0291748046875,\n",
       " -0.197265625,\n",
       " -0.04541015625,\n",
       " -0.06494140625,\n",
       " -0.01129150390625,\n",
       " 0.06787109375,\n",
       " 0.1923828125,\n",
       " 0.1533203125,\n",
       " 0.11474609375,\n",
       " -0.1298828125,\n",
       " 0.08984375,\n",
       " -0.1328125,\n",
       " 0.01556396484375,\n",
       " -0.03173828125,\n",
       " -0.10791015625,\n",
       " -0.287109375,\n",
       " 0.07763671875,\n",
       " 0.04052734375,\n",
       " 0.01312255859375,\n",
       " -0.1318359375,\n",
       " 0.02197265625,\n",
       " 0.08935546875,\n",
       " -0.0162353515625,\n",
       " -0.27734375,\n",
       " 0.042236328125,\n",
       " 0.1259765625,\n",
       " 0.146484375,\n",
       " 0.236328125,\n",
       " -0.08056640625,\n",
       " 0.1083984375,\n",
       " 0.10791015625,\n",
       " 0.10205078125,\n",
       " -0.09228515625,\n",
       " 0.041748046875,\n",
       " 0.099609375,\n",
       " -0.1513671875,\n",
       " -0.27734375,\n",
       " -0.158203125,\n",
       " 0.16796875,\n",
       " -0.1650390625,\n",
       " -0.4609375,\n",
       " -0.1494140625,\n",
       " -0.017333984375,\n",
       " 0.1083984375,\n",
       " 0.28125,\n",
       " 0.111328125,\n",
       " 0.061279296875,\n",
       " -0.275390625,\n",
       " -0.1416015625,\n",
       " -0.01312255859375,\n",
       " 0.01177978515625,\n",
       " -0.1787109375,\n",
       " 0.0120849609375,\n",
       " -0.0028533935546875,\n",
       " 0.1591796875,\n",
       " -0.00750732421875,\n",
       " -0.061767578125,\n",
       " 0.1357421875,\n",
       " 0.1572265625,\n",
       " 0.111328125,\n",
       " 0.07421875,\n",
       " -0.1591796875,\n",
       " -0.2041015625,\n",
       " -0.13671875,\n",
       " 0.030517578125,\n",
       " -0.0732421875,\n",
       " -0.0869140625,\n",
       " 0.2470703125,\n",
       " -0.126953125,\n",
       " -0.1474609375,\n",
       " 0.376953125,\n",
       " 0.30078125,\n",
       " 0.1748046875,\n",
       " 0.06982421875,\n",
       " 0.10498046875,\n",
       " -0.283203125,\n",
       " 0.07470703125,\n",
       " 0.08837890625,\n",
       " -0.09423828125,\n",
       " 0.06298828125,\n",
       " -0.064453125,\n",
       " 0.146484375,\n",
       " -0.146484375,\n",
       " -0.1943359375,\n",
       " -0.0093994140625,\n",
       " 0.0023956298828125,\n",
       " -0.2890625,\n",
       " 0.0196533203125,\n",
       " 0.0021209716796875,\n",
       " 0.0079345703125,\n",
       " 0.0279541015625,\n",
       " -0.039794921875,\n",
       " -0.388671875,\n",
       " 0.2314453125,\n",
       " -0.031494140625,\n",
       " 0.006683349609375,\n",
       " -0.07275390625,\n",
       " 0.0208740234375,\n",
       " -0.11669921875,\n",
       " -0.1220703125,\n",
       " -0.310546875,\n",
       " 0.0615234375,\n",
       " 0.10791015625,\n",
       " -0.2734375,\n",
       " 0.08544921875,\n",
       " 0.0927734375,\n",
       " -0.08837890625,\n",
       " -0.26171875,\n",
       " 0.1630859375,\n",
       " -0.1845703125,\n",
       " -0.181640625,\n",
       " -0.1650390625,\n",
       " -0.322265625,\n",
       " 0.138671875,\n",
       " 0.251953125,\n",
       " -0.1533203125,\n",
       " 0.412109375,\n",
       " 0.01080322265625,\n",
       " -0.283203125,\n",
       " -0.20703125,\n",
       " 0.10693359375,\n",
       " -0.115234375,\n",
       " 0.15625,\n",
       " 0.11376953125,\n",
       " 0.138671875,\n",
       " -0.171875,\n",
       " 0.13671875,\n",
       " 0.004974365234375,\n",
       " 0.138671875,\n",
       " 0.053955078125,\n",
       " 0.0546875,\n",
       " -0.193359375,\n",
       " -0.059326171875,\n",
       " -0.054931640625,\n",
       " 0.091796875,\n",
       " 0.1259765625,\n",
       " -0.1787109375,\n",
       " -0.1787109375,\n",
       " 0.0216064453125,\n",
       " -0.0213623046875,\n",
       " 0.396484375,\n",
       " -0.08154296875,\n",
       " 0.01422119140625,\n",
       " -0.014404296875,\n",
       " -0.150390625,\n",
       " 0.32421875,\n",
       " 0.037109375,\n",
       " -0.036865234375,\n",
       " 0.09326171875,\n",
       " -0.1318359375,\n",
       " 0.1357421875,\n",
       " 0.1513671875,\n",
       " 0.10400390625,\n",
       " 0.1875,\n",
       " 0.10546875,\n",
       " 0.017822265625,\n",
       " -0.228515625,\n",
       " 2.7184944695369784,\n",
       " 0.4452938184091016]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check._get_dist('employers','employees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['____', 'so that we'],\n",
       " ['____', 'san'],\n",
       " ['that ____', \"that's been\"],\n",
       " [\"i've run out\", \"right now it's 7 instead\"],\n",
       " ['employers', 'employees'],\n",
       " ['works that', 'worst and'],\n",
       " ['____', 'was mentioned earlier'],\n",
       " [\"it's they have mental like\", \"but it's a mental\"],\n",
       " ['white obviously', 'like this i think though obviously'],\n",
       " ['', \"until i'm\"],\n",
       " [\"is like all that's\", 'was all about'],\n",
       " ['honest', 'honestly'],\n",
       " ['i totally', 'totally'],\n",
       " ['as', 'that is'],\n",
       " ['favorable', 'favorably'],\n",
       " ['',\n",
       "  \"028057 s2 i'm sorry the question again was 028078 s1 sorry why do you think it's important to engage and empower students\"],\n",
       " ['spring', '____'],\n",
       " ['i saw the', 'the'],\n",
       " ['urgent', '____'],\n",
       " ['whites just', 'whites in just'],\n",
       " ['justice is', 'injustice is'],\n",
       " ['', 'entrepreneur'],\n",
       " ['casinos our', 'casinos the'],\n",
       " [\"s1 they've might\", \"s2 they might've\"],\n",
       " ['bend', 'bent'],\n",
       " [\"they've\", 'that have'],\n",
       " [\"something i haven't\", 'jumping ahead'],\n",
       " ['defaced', 'debased'],\n",
       " ['as opposed', 'and would post'],\n",
       " ['are headed', 'wanna head'],\n",
       " ['', 'though'],\n",
       " ['got', 'brought'],\n",
       " ['that', 'than'],\n",
       " ['grand', 'great'],\n",
       " ['body', 'body too'],\n",
       " ['maybe worth ____', 'may be worth vivian'],\n",
       " ['hazelton an intern', 'hazelden i interned'],\n",
       " ['take in', 'taking'],\n",
       " ['that month', '____'],\n",
       " ['about', 'about tfn events'],\n",
       " ['made', 'it made'],\n",
       " ['line', 'plane'],\n",
       " ['on the', 'an'],\n",
       " ['waste and', 'wasted but'],\n",
       " ['particularly', 'particular'],\n",
       " ['everything', 'that sort of thing'],\n",
       " ['windsor', 'vint cerf'],\n",
       " ['____', 'it right'],\n",
       " ['pointing', 'putting it'],\n",
       " ['that', \"graham's\"],\n",
       " ['and answered', 'to answer'],\n",
       " ['point to this this', 'pointed this out that this'],\n",
       " ['building monitored', 'build and monitor'],\n",
       " ['crossroads', 'crossroads meeting'],\n",
       " ['gloria', 'glorious'],\n",
       " ['terribly this is', \"terribly and there's\"],\n",
       " ['28', '20 inked'],\n",
       " ['problem', '____'],\n",
       " ['moment and', \"moment i'm\"],\n",
       " ['____ was', \"ian lang's\"],\n",
       " ['show you', 'assure you'],\n",
       " ['gracing', 'grace and'],\n",
       " ['musculotendionous', 'musculotendinous'],\n",
       " ['was you know', 'was'],\n",
       " ['module', 'of them also look'],\n",
       " ['provision for', 'population of'],\n",
       " ['the things like', 'it seems like'],\n",
       " [\"it's different\", \"let's do it\"],\n",
       " ['kind of independent', 'kinda independent'],\n",
       " ['make', 'be making'],\n",
       " ['that give', 'where'],\n",
       " ['there', 'either'],\n",
       " ['____', \"people you hadn't seen\"],\n",
       " ['background', '040008 s2 are we done overlapping'],\n",
       " ['____',\n",
       "  \"so it wasn't that just russia and america basically that in australia they were supporting them ____\"],\n",
       " ['do', \"you're\"],\n",
       " ['rough', 'roof'],\n",
       " ['smoking', 'smoke in'],\n",
       " ['ask not', 'know'],\n",
       " ['this is', \"there's just\"],\n",
       " ['was gonna visit me', 'would go to visiting'],\n",
       " ['be around the fence', 'their own defense'],\n",
       " ['strategic ____ is', 'strategic is'],\n",
       " ['carrots', 'carriage'],\n",
       " ['we cut', 're-cut'],\n",
       " ['____ provider', 'to always ask your provider'],\n",
       " ['____', 'on this for awhile'],\n",
       " ['', \"okay i'll make this up 032010 s1\"],\n",
       " [\"doesn't\", \"just didn't\"],\n",
       " ['anywhere', 'anyway'],\n",
       " ['layed', 'laid'],\n",
       " ['', \"it's a finger tip this long\"],\n",
       " ['that ____ us', \"that's the message\"],\n",
       " ['here is', \"and that's\"],\n",
       " ['hawaiian culture', 'uruguayan culture'],\n",
       " [\"thing i'm sort of weird\", 'thing that was sorta weird excuse me'],\n",
       " ['lead', 'led'],\n",
       " ['this policy', 'the ____'],\n",
       " ['put', 'with'],\n",
       " ['30007', '3007'],\n",
       " ['pilots', 'pilot'],\n",
       " ['underground', 'on the ground'],\n",
       " ['usually', 'either'],\n",
       " ['benefiting well a', 'benefiting from it right a'],\n",
       " ['do the', 'did a'],\n",
       " ['has a', 'and her'],\n",
       " ['in other things', 'another thing is'],\n",
       " ['in', 'and hit'],\n",
       " ['drug but like a', 'drug or'],\n",
       " ['barely larger', 'fairly large or'],\n",
       " ['bring', 'doing'],\n",
       " ['2 to get me', '250'],\n",
       " ['', 'thank you very much'],\n",
       " [\"i'll\", \"i've gotta\"],\n",
       " ['other 046064 s2', 'other'],\n",
       " ['____', 'carrots'],\n",
       " ['taking', 'talking'],\n",
       " ['fix', 'fixture'],\n",
       " ['____', 'alright now'],\n",
       " ['review', 'review chuckle'],\n",
       " ['did', 'did this is debbie'],\n",
       " [\"smoking alcohol 'cause\", \"smoke and alcohol 'cause\"],\n",
       " ['this location', 'like the flotation'],\n",
       " ['so be it', 'over here'],\n",
       " ['interesting but it', 'interesting but'],\n",
       " ['', 'maintain'],\n",
       " ['guess on', 'guess'],\n",
       " ['silence right', 'silence'],\n",
       " ['it background conversation', 'it we should just probably get a'],\n",
       " ['base shift having', 'base you have to have an'],\n",
       " ['____', 'who'],\n",
       " ['____', 'search for'],\n",
       " ['s no', 's1 no'],\n",
       " ['body 012442 s1', 'body'],\n",
       " [\"it's gold or\", 'its goals are'],\n",
       " ['usually', 'actually'],\n",
       " ['our case', 'actually'],\n",
       " ['black for capital', 'blackford capital'],\n",
       " [\"i'm asking\", 'that was gonna be'],\n",
       " ['____', 'i need to pack another'],\n",
       " ['____', 'when'],\n",
       " ['their', 'digital'],\n",
       " ['____', 'time'],\n",
       " ['told us there would', \"promised that there'd\"],\n",
       " ['works power', 'horsepower'],\n",
       " ['system right', 'instrument'],\n",
       " [\"you're\", 'are'],\n",
       " ['tickle cream', 'techno cream'],\n",
       " ['they gained', 'again'],\n",
       " ['god ____ narcan for', 'god or what or narcan but for'],\n",
       " ['something 024006 s2', 'something'],\n",
       " [\"didn't do\", 'did'],\n",
       " ['____', 'that you have'],\n",
       " ['every', 'ever'],\n",
       " ['necessary', 'necessarily'],\n",
       " ['s1', 's'],\n",
       " ['them', 'the bunnies'],\n",
       " ['load and', 'loading'],\n",
       " ['it especially ____', 'it as opposed to what fun activity you did'],\n",
       " ['deminimus', 'de minimis'],\n",
       " ['one-and-a-half percent', '15'],\n",
       " ['siding', 'sidings'],\n",
       " ['on a', 'from'],\n",
       " ['friday', 'frightening'],\n",
       " ['help will', \"help we'll\"],\n",
       " ['relaxed and sitting', 'relaxed sitting'],\n",
       " ['____', 'he'],\n",
       " ['is if', 'is the'],\n",
       " ['structure', 'characters'],\n",
       " ['go-to-guy 021117 s2 laughter 021128 s1', 'go to guy'],\n",
       " ['', \"like 107153 s1 and i'm sure 107158 s2 you\"],\n",
       " ['bellow', 'below'],\n",
       " ['', \"you're whatever it is\"],\n",
       " ['programs', 'proven'],\n",
       " ['movements and', 'own movements and'],\n",
       " [\"it's relaying\", 'i was relearning'],\n",
       " ['one is', 'winds'],\n",
       " ['he hang', 'hung'],\n",
       " ['know like', 'know'],\n",
       " [\"it'd be something\", 'recently'],\n",
       " ['', 'a way of yeah it could be'],\n",
       " [\"escalating it's\", 'escalating is'],\n",
       " ['curve', 'priority'],\n",
       " ['you would have an infinite then', ''],\n",
       " ['worse', 'worsen'],\n",
       " ['in-comm thermostat', 'inncom thermostat'],\n",
       " ['you', 'who'],\n",
       " ['gonna', 'going to be'],\n",
       " ['up', \"'em\"],\n",
       " ['____', 'guys'],\n",
       " ['no no', 'no'],\n",
       " ['those are', \"as they're\"],\n",
       " ['of jeff', 'for jeff'],\n",
       " ['totally', 'torah'],\n",
       " ['gait', 'gait and'],\n",
       " ['', 'me the most helpful thing you can do to'],\n",
       " ['is ____ source', 'is something source'],\n",
       " ['oh', 'well then'],\n",
       " ['member of', 'number for'],\n",
       " ['run', 'bring'],\n",
       " ['commit to', 'convince them'],\n",
       " ['faithful nation', 'faith formation'],\n",
       " ['____', 'measures'],\n",
       " ['garden you', 'gardens too you'],\n",
       " ['dress', 'dress good'],\n",
       " ['is very bloody right i mean', 'variability'],\n",
       " ['they develop', \"they've developed\"],\n",
       " ['i to', 'into'],\n",
       " [\"family's\", 'families'],\n",
       " ['down', 'up'],\n",
       " ['fiber nutrients', 'phytonutrients'],\n",
       " ['kennedy', 'trinity'],\n",
       " ['the waterbed', 'water'],\n",
       " ['the desert eyes', '____ i was'],\n",
       " ['check count', 'accountant'],\n",
       " ['more i feel like', 'more'],\n",
       " ['dairies', 'dairy'],\n",
       " ['know was', 'tell woman'],\n",
       " ['i mean some this and', \"certainly isn't\"],\n",
       " ['idea of', 'ideal'],\n",
       " ['stylist', 'stylish'],\n",
       " [\"you've\", ''],\n",
       " ['s3 and', 's and'],\n",
       " ['flexible', 'flexible la la'],\n",
       " ['psychedelics', 'psychedelics right'],\n",
       " ['amazing yeah know', 'amazing'],\n",
       " ['____', 'jess'],\n",
       " ['like all', 'r'],\n",
       " ['chance', 'suggestions'],\n",
       " [\"there he's\", \"there who's\"],\n",
       " ['how that a', 'the helvetica'],\n",
       " ['are willing to', \"that wouldn't even\"],\n",
       " ['re-way', 'reweigh'],\n",
       " ['just did some experimenting', \"just if it's an experiment in\"],\n",
       " ['kind', 'a sample'],\n",
       " ['____ we', 'torah we'],\n",
       " ['back through', '____'],\n",
       " ['let it on', '____'],\n",
       " ['dnn', 'dan in'],\n",
       " ['to take it', 'the trach'],\n",
       " ['intro', 'intro like'],\n",
       " [\"well there's\", 'well there are'],\n",
       " ['people i was like', 'people of like'],\n",
       " ['month right', 'most part'],\n",
       " ['that', 'that way'],\n",
       " ['faith', 'face'],\n",
       " ['', 'tension'],\n",
       " ['they fear to', 'they here'],\n",
       " ['is like', 'has'],\n",
       " ['big', 'breaks'],\n",
       " [\"second that's it those\", 'second i said those'],\n",
       " ['____', 'into a question'],\n",
       " ['i feel', 'was'],\n",
       " ['inside', 'in in time'],\n",
       " ['restaurateur', 'restauranteur'],\n",
       " ['____', 'unless you can'],\n",
       " ['of it', 'that'],\n",
       " ['cause', 'put'],\n",
       " ['just', 'it does'],\n",
       " ['tended to', 'have attempted'],\n",
       " ['want to', 'would'],\n",
       " ['say', 'saying'],\n",
       " ['berkeley the ____', 'berkeley directors'],\n",
       " ['', 'earth'],\n",
       " [\"don't\", \"don't and\"],\n",
       " ['when it comes', 'about being close'],\n",
       " ['infringement', 'impingement'],\n",
       " ['had', 'hit'],\n",
       " [\"'til\", 'till'],\n",
       " ['say', 'tell me'],\n",
       " ['no', 'definitely not chuckle'],\n",
       " ['then', 'then another thing'],\n",
       " ['k', 'okay'],\n",
       " ['____', \"it's a bunch of interns\"],\n",
       " ['until', 'to the'],\n",
       " ['appreciate that man', 'preach to them and'],\n",
       " ['guards ____', 'guards vaughn wedeking'],\n",
       " ['mens', 'men'],\n",
       " ['', \"girls i don't know most of the\"],\n",
       " ['in a minute', \"that's been admitted\"],\n",
       " ['', 'the typical'],\n",
       " [\"census who've worked\", 'scientists who work'],\n",
       " ['faculty lead', 'faculty-led'],\n",
       " ['on', 'hard'],\n",
       " ['kid', 'kick'],\n",
       " ['exemption', 'exception'],\n",
       " ['contacts matters and', 'context matters and'],\n",
       " ['pumpkin', 'pumpking'],\n",
       " ['filling', 'filing'],\n",
       " ['very differently', '____'],\n",
       " ['____', 'much'],\n",
       " [\"he's like\", 'he said'],\n",
       " ['replaced', 'replace'],\n",
       " ['today or but', 'chuckle to the hoop but'],\n",
       " ['on', 'under'],\n",
       " [\"familia it's spanish\", 'familia the spanish for family'],\n",
       " ['inflection', 'and flexion'],\n",
       " ['more 011200 s1', 'more'],\n",
       " ['summer and that', 'some are the'],\n",
       " ['responsibility', 'my position responsibility'],\n",
       " [\"dan's taking\", \"than's stake in\"],\n",
       " ['hold', 'hone'],\n",
       " ['nuded', 'muted'],\n",
       " ['figure it', 'figured'],\n",
       " ['day', 'phase'],\n",
       " ['part-timely', 'part-time need'],\n",
       " ['', 'divine'],\n",
       " ['for being', 'to be'],\n",
       " [\"you're teaching and\", ''],\n",
       " ['instance', 'incidence'],\n",
       " ['in discipline', 'and disciplined'],\n",
       " ['then', 'down'],\n",
       " [\"____ it'll\", \"he doesn't\"],\n",
       " ['mild ____ release', 'myofascial release'],\n",
       " ['pharaoh they', 'sparrow they'],\n",
       " ['can say of', 'consider'],\n",
       " ['____', 'biographies'],\n",
       " ['gooey', 'gui'],\n",
       " ['committed a', \"didn't commit the\"],\n",
       " ['that was after', 'after'],\n",
       " ['key words my', 'keywords so my'],\n",
       " ['only handle', 'only'],\n",
       " ['every', 'of the'],\n",
       " ['', 'or strapped me'],\n",
       " ['have been', 'are'],\n",
       " ['grown the', 'risen'],\n",
       " ['care', 'cared'],\n",
       " ['your feeling is', \"you're being\"],\n",
       " ['nerd', 'nerd is cool now'],\n",
       " ['operating down there', 'operated under'],\n",
       " ['name ecollegehavardedu', 'name at collegehavardedu'],\n",
       " ['like giving', 'giving'],\n",
       " [\"'em all\", 'a mall'],\n",
       " ['parts', 'parcel'],\n",
       " ['function', 'functional'],\n",
       " ['off', \"like i'll have\"],\n",
       " ['price momentum also', 'price momentum oscillator'],\n",
       " ['that we', 'we'],\n",
       " ['soundboard', 'sounding board'],\n",
       " ['we know that', '____'],\n",
       " ['therefore', 'so therefore'],\n",
       " ['day it makes', 'time so'],\n",
       " ['kitchen at', 'kitchenette'],\n",
       " ['crash', '____'],\n",
       " ['africa organizations and', 'african organizations and'],\n",
       " ['____', 'in'],\n",
       " [\"____ that's how to write\", \"it's not the right\"],\n",
       " ['a so', 'some'],\n",
       " ['word the', 'word because the'],\n",
       " ['worth', 'wih'],\n",
       " ['list there', 'lister'],\n",
       " ['guess i', 'guess'],\n",
       " ['____', 'stigs'],\n",
       " ['dealt', 'felt'],\n",
       " ['____', 'laughed out'],\n",
       " ['soil', 'fall'],\n",
       " ['clear', \"clear i don't wanna ramble\"],\n",
       " ['these', \"they've\"],\n",
       " ['arm as you', 'alarm you'],\n",
       " ['raising', 'big thinkers you need'],\n",
       " [\"i'm\", \"well i'm\"],\n",
       " ['and do', 'do'],\n",
       " ['the', 'new'],\n",
       " ['right ____', 'like parenting chuckle'],\n",
       " ['the process', 'multiple tasks'],\n",
       " ['', '000303 s4 the pie'],\n",
       " ['effect', 'impact'],\n",
       " ['hands', 'hints'],\n",
       " ['communicate', 'communicate and'],\n",
       " ['course i blamed', \"course i'd blame\"],\n",
       " ['pastor', 'pastoral'],\n",
       " ['my vegetables', 'the vegetables'],\n",
       " ['sheet', 'sheets'],\n",
       " ['then probably mentioned', 'then now that you mention'],\n",
       " ['historic yeah laughter', 'absurd yeah laughter 057290 s1'],\n",
       " ['timed at', 'tied to'],\n",
       " ['in a', 'on the'],\n",
       " [\"you're getting\", 'that you get'],\n",
       " ['it works', 'you list it'],\n",
       " ['bakersfield', 'meadows field'],\n",
       " ['look', 'but look'],\n",
       " ['they', \"they've\"],\n",
       " ['on like that', \"i'm like that\"],\n",
       " ['op', 'ops'],\n",
       " ['run in', 'run and'],\n",
       " ['u-dub', 'u-dub 000514 s1'],\n",
       " ['that risks', 'at-risk'],\n",
       " ['you', 'you david'],\n",
       " ['dot1', 'dot-one'],\n",
       " ['background conversation',\n",
       "  \"003352 s1 what are you going to do in denver 003363 s2 what am i gonna do in denver 003376 s1 yeah besides the conference 003392 s2 what 003398 s1 what are you gonna do outside the conference 003441 s2 i'm excited to explore nature around denver 'cause i've never been there before 003485 s1 you ever heard of golden 003491 s2 of what 003503 s1 golden 003509 s2 no 003518 s1 ____ 003535 s2 okay okay\"],\n",
       " ['____', 'gets reviewed and'],\n",
       " ['questions', 'question is'],\n",
       " ['thing', 'then'],\n",
       " ['intelligent', 'intelligence'],\n",
       " ['maybe', 'me just'],\n",
       " ['aid', 'aide'],\n",
       " ['old very outdated', 'outdated'],\n",
       " ['something', 'something it'],\n",
       " ['____', 'franco'],\n",
       " ['____ step about faith', 'step without pain'],\n",
       " ['____', 'menifee'],\n",
       " ['that we', 'that but we'],\n",
       " ['hassan', 'hudson'],\n",
       " ['saved', 'save'],\n",
       " ['effects of', 'effective'],\n",
       " ['that scale', 'scale'],\n",
       " ['artists', 'our artists'],\n",
       " ['s3', 's1 okay'],\n",
       " ['vote', 'come out']]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check._FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tPredicted:\n",
      "\t\tmin. maj.\n",
      "Actual:\t min. [5940  536]\n",
      "    \t maj. [1092 1067]\n"
     ]
    }
   ],
   "source": [
    "#(84.5 with 612 features) using only 12 features -- 82.8\n",
    "#increase minibatch to 64 -- 82.5\n",
    "# change lr from .09,.005 to .9,.05 -- peaks at 824 pass 40, ends 822\n",
    "# .9 to .0005 -- 8218 at the end\n",
    "check.check_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tPredicted:\n",
      "\t\tmin. maj.\n",
      "Actual:\t min. [5867  492]\n",
      "    \t maj. [ 916 1360]\n"
     ]
    }
   ],
   "source": [
    "check.check_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEEIIAUBBIIQQEkFBIIQQAgD4f0M7MfbnZH1QAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18e9e6450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(check._cost_list))[::100],check._cost_list[::100]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x4b8c3b910>]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEACAYAAAC6d6FnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2cd6f5d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(range(len(check._cost_list))[::100],check._cost_list[::100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,1,2,1,2,2,1,2,1,1,1,2,No error,2,1,1,1,1,1,1,2,1,1,1,1,1,1\n"
     ]
    }
   ],
   "source": [
    "check.predict(os.path.join(path,'data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tPredicted:\n",
      "\t\tmin. maj.\n",
      "Actual:\t min. [5794  441]\n",
      "    \t maj. [1120 1280]\n"
     ]
    }
   ],
   "source": [
    "check.check_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# just checking again with default pattern\n",
    "# just to compare errors. with 83.232 it was: \n",
    "#(top left top right bot left bot right) \n",
    "######## '[\\w+\\']+': 5740-495-1022-1378 (is that first plus supposed to be there?)\n",
    "\n",
    "#default: 5725-530-929-1407 BUT 437 bad\n",
    "\n",
    "# '[\\w\\']+(\\-[\\w]+)?': 5751-484-1127-1273\n",
    "\n",
    "without the plus\n",
    "#'[\\w\\']+': 5720-515-1023-1377\n",
    "\n",
    "# shouldn'e actually make a difference; there are no plusses in there\n",
    "# but run again... 5794-441-1120-1280\n",
    "\n",
    "# don't forget to delete self.bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8635\n",
      "8591\n"
     ]
    }
   ],
   "source": [
    "print(sum([5740,495,1022,1378]))\n",
    "print(sum([5725,530,929,1407]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_pattern = '[\\w\\']+(\\-[\\w]+)?'\n",
    "len(check.bad) 0\n",
    "82.682\n",
    "\n",
    "token_pattern = '[\\w+\\']+'\n",
    "len(check.bad) 0\n",
    "83.232"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74571"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(check.bad) ##438\n",
    "# check.bad[258] ##74571\n",
    "# check.raw_X[74571] ##array(['', ''], dtype='|S2952')\n",
    "# manually deleted it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258\n"
     ]
    }
   ],
   "source": [
    "for i,row in enumerate(check.raw_X[check.bad]):\n",
    "    try:\n",
    "        CountVectorizer(token_pattern='[\\w\\']+(\\-[\\w]+)?').fit([row[0],row[1]]).get_feature_names()\n",
    "    except:\n",
    "        print(i) #just 258"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,1,2,1,1,2,1,2,1,1,1,2,No error,2,1,1,1,1,1,2,2,1,1,1,1,2,1\n"
     ]
    }
   ],
   "source": [
    "check.predict(os.path.join(path,'data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# original\n",
    "1 loop, best of 3: 10.6 s per loop\n",
    "# moving graph build to beginning of predict -- ramifications for batches and such??\n",
    "1 loop, best of 3: 4.84 s per loop\n",
    "# initialize session first, but all unknowns except no error\n",
    "1 loop, best of 3: 526 ms per loop\n",
    "# forgot to indent everything after tf.Session()... winnar\n",
    "1 loop, best of 3: 1.12 s per loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
