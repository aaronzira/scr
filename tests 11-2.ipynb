{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is one pen'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'\\ba\\b','one','this is a pen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import os\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "import numpy as np\n",
    "#this is a different euclidean distances from the model\n",
    "from sklearn.metrics.pairwise import euclidean_distances as pair_euclidean_distances\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pyemd import emd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = '/Users/Rutherford/Desktop/data'\n",
    "_save_path = os.path.join(data_path,'model.ckpt')\n",
    "epsilon = 1e-4\n",
    "\n",
    "binary_file = os.path.join(data_path,\n",
    "                           'GoogleNews-vectors-negative300.bin')\n",
    "w2v_dat = os.path.join(data_path,'embed.dat')\n",
    "w2v_vocab = os.path.join(data_path,'embed.vocab')\n",
    "\n",
    "if not os.path.exists(w2v_dat):\n",
    "    print(\"Caching word embeddings in memmapped format.                     Please be patient...\")\n",
    "    wv = Word2Vec.load_word2vec_format(\n",
    "        binary_file,binary=True)\n",
    "    fp = np.memmap(w2v_dat, dtype=np.double,\n",
    "                   mode='w+', shape=wv.syn0.shape)\n",
    "    fp[:] = wv.syn0[:]\n",
    "    with open(w2v_vocab, \"w\") as f:\n",
    "        for _, w in sorted((voc.index, word)                                    for word, voc in wv.vocab.items()):\n",
    "            print(w, file=f)\n",
    "    del fp, wv\n",
    "\n",
    "# create word embeddings and mapping of vocabulary item to index\n",
    "embeddings = np.memmap(w2v_dat, dtype=np.float64,\n",
    "                            mode=\"r\", shape=(3000000, 300))\n",
    "with open(w2v_vocab) as f:\n",
    "    vocab_list = map(lambda string: string.strip(), f.readlines())\n",
    "vocab_dict = {w: i for i, w in enumerate(vocab_list)}\n",
    "\n",
    "# mean of 20 rarest words, used as a stand-in for pairwise distances\n",
    "# if a word is out-of-vocabulary\n",
    "avg_rare_word = np.mean(np.vstack((embeddings[-20:])),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_1 = 'this is a pen'\n",
    "s_2 = 'wishes to men'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(token_pattern='[\\w\\']+').fit([s_1, s_2])\n",
    "features = np.asarray(vect.get_feature_names())\n",
    "\n",
    "# get 'flow' vectors\n",
    "v_1, v_2 = vect.transform([s_1, s_2])\n",
    "v_1 = v_1.toarray().ravel().astype(np.float64)\n",
    "v_2 = v_2.toarray().ravel().astype(np.float64)\n",
    "\n",
    "# normalize vectors so as not to reward shorter strings in WMD\n",
    "v_1 /= (v_1.sum()+epsilon)\n",
    "v_2 /= (v_2.sum()+epsilon)\n",
    "\n",
    "# for each out-of-vocabulary item, use the average of the 20\n",
    "# rarest words' embeddings to represent it in the distance calc\n",
    "bad = len([w for w in features if w not in vocab_dict])\n",
    "bad_rows = np.asarray([avg_rare_word]*bad)\n",
    "\n",
    "# get distance matrix for words in both strings\n",
    "W_ = embeddings[[vocab_dict[w] for w in features if w in vocab_dict]]\n",
    "\n",
    "if bad_rows.shape[0]>0:\n",
    "    W_ = np.vstack((W_,bad_rows))\n",
    "\n",
    "# use both euclidean and cosine dists (cosine dist is 1-cosine sim)\n",
    "D_pair_euclidean = pair_euclidean_distances(W_).astype(np.float64)\n",
    "D_euclidean = euclidean_distances(W_).astype(np.float64)\n",
    "D_cosine = 1.-cosine_similarity(W_,).astype(np.float64)\n",
    "\n",
    "# using EMD (Earth Mover's Distance) from PyEMD\n",
    "distances_pair_euclidean = emd(v_1,v_2,D_pair_euclidean)\n",
    "distances_euclidean = emd(v_1,v_2,D_euclidean)\n",
    "distances_cosine = emd(v_1,v_2,D_cosine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 300)\n",
      "(1, 300)\n",
      "(1, 300)\n",
      "(1, 300)\n",
      "(1, 300)\n",
      "(1, 300)\n",
      "(1, 300)\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(token_pattern='[\\w\\']+').fit([s_1, s_2])\n",
    "features = np.asarray(vect.get_feature_names())\n",
    "\n",
    "# get 'flow' vectors\n",
    "v_1, v_2 = vect.transform([s_1, s_2])\n",
    "v_1 = v_1.toarray().ravel().astype(np.float64)\n",
    "v_2 = v_2.toarray().ravel().astype(np.float64)\n",
    "\n",
    "# normalize vectors so as not to reward shorter strings in WMD\n",
    "v_1 /= (v_1.sum()+epsilon)\n",
    "v_2 /= (v_2.sum()+epsilon)\n",
    "\n",
    "bad_row = np.asarray([avg_rare_word])\n",
    "\n",
    "W_ = np.ndarray([0,300])\n",
    "# get distance matrix for words in both strings\n",
    "for w in features:\n",
    "    if w in vocab_dict:\n",
    "        #print(embeddings[vocab_dict[w]].shape)\n",
    "        print(embeddings[[vocab_dict[w]]].shape)\n",
    "        \n",
    "        W_ = np.append(W_,embeddings[[vocab_dict[w]]],axis=0)\n",
    "    else:\n",
    "        print(bad_row.shape)\n",
    "        W_ = np.append(W_,bad_row,axis=0)\n",
    "\n",
    "# use both euclidean and cosine dists (cosine dist is 1-cosine sim)\n",
    "D_pair_euclidean = pair_euclidean_distances(W_).astype(np.float64)\n",
    "D_euclidean = euclidean_distances(W_).astype(np.float64)\n",
    "D_cosine = 1.-cosine_similarity(W_,).astype(np.float64)\n",
    "\n",
    "# using EMD (Earth Mover's Distance) from PyEMD\n",
    "distances_pair_euclidean = emd(v_1,v_2,D_pair_euclidean)\n",
    "distances_euclidean = emd(v_1,v_2,D_euclidean)\n",
    "distances_cosine = emd(v_1,v_2,D_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.34285048785\n",
      "2.34285048785\n",
      "0.68416614785\n"
     ]
    }
   ],
   "source": [
    "print(distances_pair_euclidean)\n",
    "print(distances_euclidean)\n",
    "print(distances_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_ = np.ndarray([0,300])\n",
    "# get distance matrix for words in both strings\n",
    "for w in features:\n",
    "    if w in vocab_dict:\n",
    "        W_ = np.append(W_,embeddings[[vocab_dict[w]]],axis=0)\n",
    "    else:\n",
    "        W_ = np.append(W_,bad_row,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
